{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by a simple 1D case.\n",
    "\n",
    "If $y = wx$ with $w=2$. We have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0/400 loss 8.360563278198242 W = 1.103\n",
      "epoch 1/400 loss 6.040506362915039 W = 1.237\n",
      "epoch 2/400 loss 4.364266395568848 W = 1.352\n",
      "epoch 3/400 loss 3.1531827449798584 W = 1.449\n",
      "epoch 4/400 loss 2.2781741619110107 W = 1.532\n",
      "epoch 5/400 loss 1.6459808349609375 W = 1.602\n",
      "epoch 6/400 loss 1.189220905303955 W = 1.662\n",
      "epoch 7/400 loss 0.8592120409011841 W = 1.712\n",
      "epoch 8/400 loss 0.6207807064056396 W = 1.755\n",
      "epoch 9/400 loss 0.44851434230804443 W = 1.792\n",
      "epoch 10/400 loss 0.3240514397621155 W = 1.823\n",
      "epoch 11/400 loss 0.23412704467773438 W = 1.850\n",
      "epoch 12/400 loss 0.16915678977966309 W = 1.872\n",
      "epoch 13/400 loss 0.12221580743789673 W = 1.891\n",
      "epoch 14/400 loss 0.08830098062753677 W = 1.908\n",
      "epoch 15/400 loss 0.06379739940166473 W = 1.922\n",
      "epoch 16/400 loss 0.04609359800815582 W = 1.933\n",
      "epoch 17/400 loss 0.03330262750387192 W = 1.943\n",
      "epoch 18/400 loss 0.024061203002929688 W = 1.952\n",
      "epoch 19/400 loss 0.017384272068738937 W = 1.959\n",
      "epoch 20/400 loss 0.012560101225972176 W = 1.965\n",
      "epoch 21/400 loss 0.009074684232473373 W = 1.970\n",
      "epoch 22/400 loss 0.006556451786309481 W = 1.975\n",
      "epoch 23/400 loss 0.00473701860755682 W = 1.979\n",
      "epoch 24/400 loss 0.0034224996343255043 W = 1.982\n",
      "epoch 25/400 loss 0.0024727419950067997 W = 1.985\n",
      "epoch 26/400 loss 0.0017865439876914024 W = 1.987\n",
      "epoch 27/400 loss 0.0012907866621389985 W = 1.989\n",
      "epoch 28/400 loss 0.0009325945866294205 W = 1.991\n",
      "epoch 29/400 loss 0.0006738059455528855 W = 1.992\n",
      "epoch 30/400 loss 0.00048682093620300293 W = 1.993\n",
      "epoch 31/400 loss 0.00035172078059986234 W = 1.994\n",
      "epoch 32/400 loss 0.0002541200374253094 W = 1.995\n",
      "epoch 33/400 loss 0.00018360494868829846 W = 1.996\n",
      "epoch 34/400 loss 0.0001326513011008501 W = 1.996\n",
      "epoch 35/400 loss 9.583951032254845e-05 W = 1.997\n",
      "epoch 36/400 loss 6.924533226992935e-05 W = 1.997\n",
      "epoch 37/400 loss 5.003189289709553e-05 W = 1.998\n",
      "epoch 38/400 loss 3.614698653109372e-05 W = 1.998\n",
      "epoch 39/400 loss 2.6116864319192246e-05 W = 1.998\n",
      "epoch 40/400 loss 1.887076723505743e-05 W = 1.999\n",
      "epoch 41/400 loss 1.363299543299945e-05 W = 1.999\n",
      "epoch 42/400 loss 9.850802598521113e-06 W = 1.999\n",
      "epoch 43/400 loss 7.117675522749778e-06 W = 1.999\n",
      "epoch 44/400 loss 5.142520421941299e-06 W = 1.999\n",
      "epoch 45/400 loss 3.7151312426431105e-06 W = 1.999\n",
      "epoch 46/400 loss 2.683968432393158e-06 W = 1.999\n",
      "epoch 47/400 loss 1.93883079191437e-06 W = 2.000\n",
      "epoch 48/400 loss 1.400623659719713e-06 W = 2.000\n",
      "epoch 49/400 loss 1.0117962574440753e-06 W = 2.000\n",
      "epoch 50/400 loss 7.310032401619537e-07 W = 2.000\n",
      "epoch 51/400 loss 5.282138886286702e-07 W = 2.000\n",
      "epoch 52/400 loss 3.815256377492915e-07 W = 2.000\n",
      "epoch 53/400 loss 2.7558371584746055e-07 W = 2.000\n",
      "epoch 54/400 loss 1.9913836979412736e-07 W = 2.000\n",
      "epoch 55/400 loss 1.4396046310594102e-07 W = 2.000\n",
      "epoch 56/400 loss 1.0403880423837109e-07 W = 2.000\n",
      "epoch 57/400 loss 7.5203843152849e-08 W = 2.000\n",
      "epoch 58/400 loss 5.436523053958808e-08 W = 2.000\n",
      "epoch 59/400 loss 3.925687863670646e-08 W = 2.000\n",
      "epoch 60/400 loss 2.8377939997881185e-08 W = 2.000\n",
      "epoch 61/400 loss 2.053112169164706e-08 W = 2.000\n",
      "epoch 62/400 loss 1.4836519568461881e-08 W = 2.000\n",
      "epoch 63/400 loss 1.0717020160200263e-08 W = 2.000\n",
      "epoch 64/400 loss 7.718075067941754e-09 W = 2.000\n",
      "epoch 65/400 loss 5.594120722207663e-09 W = 2.000\n",
      "epoch 66/400 loss 4.048605006801154e-09 W = 2.000\n",
      "epoch 67/400 loss 2.9298945491973427e-09 W = 2.000\n",
      "epoch 68/400 loss 2.121954167932927e-09 W = 2.000\n",
      "epoch 69/400 loss 1.5347723092418164e-09 W = 2.000\n",
      "epoch 70/400 loss 1.1045386827390757e-09 W = 2.000\n",
      "epoch 71/400 loss 8.048637312185747e-10 W = 2.000\n",
      "epoch 72/400 loss 5.868088237548363e-10 W = 2.000\n",
      "epoch 73/400 loss 4.2168224467786786e-10 W = 2.000\n",
      "epoch 74/400 loss 3.085034450123203e-10 W = 2.000\n",
      "epoch 75/400 loss 2.2357937723427312e-10 W = 2.000\n",
      "epoch 76/400 loss 1.6128254287650634e-10 W = 2.000\n",
      "epoch 77/400 loss 1.1677414590849367e-10 W = 2.000\n",
      "epoch 78/400 loss 8.355982572538778e-11 W = 2.000\n",
      "epoch 79/400 loss 6.139089236967266e-11 W = 2.000\n",
      "epoch 80/400 loss 4.263256414560601e-11 W = 2.000\n",
      "epoch 81/400 loss 3.1167957104116795e-11 W = 2.000\n",
      "epoch 82/400 loss 2.0307311388023663e-11 W = 2.000\n",
      "epoch 83/400 loss 1.5347723092418164e-11 W = 2.000\n",
      "epoch 84/400 loss 1.1098677532572765e-11 W = 2.000\n",
      "epoch 85/400 loss 6.821210263296962e-12 W = 2.000\n",
      "epoch 86/400 loss 5.076827847005916e-12 W = 2.000\n",
      "epoch 87/400 loss 3.595346242946107e-12 W = 2.000\n",
      "epoch 88/400 loss 2.7746693831431912e-12 W = 2.000\n",
      "epoch 89/400 loss 1.7053025658242404e-12 W = 2.000\n",
      "epoch 90/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 91/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 92/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 93/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 94/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 95/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 96/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 97/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 98/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 99/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 100/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 101/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 102/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 103/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 104/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 105/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 106/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 107/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 108/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 109/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 110/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 111/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 112/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 113/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 114/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 115/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 116/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 117/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 118/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 119/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 120/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 121/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 122/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 123/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 124/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 125/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 126/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 127/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 128/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 129/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 130/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 131/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 132/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 133/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 134/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 135/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 136/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 137/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 138/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 139/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 140/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 141/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 142/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 143/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 144/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 145/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 146/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 147/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 148/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 149/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 150/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 151/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 152/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 153/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 154/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 155/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 156/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 157/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 158/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 159/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 160/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 161/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 162/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 163/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 164/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 165/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 166/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 167/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 168/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 169/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 170/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 171/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 172/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 173/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 174/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 175/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 176/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 177/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 178/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 179/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 180/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 181/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 182/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 183/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 184/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 185/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 186/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 187/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 188/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 189/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 190/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 191/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 192/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 193/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 194/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 195/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 196/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 197/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 198/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 199/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 200/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 201/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 202/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 203/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 204/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 205/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 206/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 207/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 208/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 209/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 210/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 211/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 212/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 213/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 214/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 215/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 216/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 217/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 218/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 219/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 220/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 221/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 222/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 223/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 224/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 225/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 226/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 227/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 228/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 229/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 230/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 231/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 232/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 233/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 234/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 235/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 236/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 237/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 238/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 239/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 240/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 241/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 242/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 243/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 244/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 245/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 246/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 247/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 248/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 249/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 250/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 251/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 252/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 253/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 254/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 255/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 256/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 257/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 258/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 259/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 260/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 261/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 262/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 263/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 264/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 265/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 266/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 267/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 268/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 269/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 270/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 271/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 272/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 273/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 274/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 275/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 276/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 277/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 278/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 279/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 280/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 281/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 282/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 283/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 284/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 285/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 286/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 287/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 288/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 289/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 290/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 291/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 292/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 293/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 294/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 295/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 296/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 297/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 298/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 299/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 300/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 301/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 302/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 303/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 304/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 305/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 306/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 307/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 308/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 309/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 310/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 311/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 312/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 313/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 314/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 315/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 316/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 317/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 318/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 319/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 320/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 321/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 322/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 323/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 324/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 325/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 326/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 327/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 328/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 329/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 330/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 331/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 332/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 333/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 334/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 335/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 336/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 337/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 338/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 339/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 340/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 341/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 342/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 343/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 344/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 345/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 346/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 347/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 348/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 349/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 350/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 351/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 352/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 353/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 354/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 355/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 356/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 357/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 358/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 359/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 360/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 361/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 362/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 363/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 364/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 365/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 366/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 367/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 368/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 369/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 370/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 371/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 372/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 373/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 374/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 375/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 376/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 377/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 378/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 379/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 380/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 381/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 382/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 383/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 384/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 385/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 386/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 387/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 388/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 389/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 390/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 391/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 392/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 393/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 394/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 395/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 396/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 397/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 398/400 loss 8.988365607365267e-13 W = 2.000\n",
      "epoch 399/400 loss 8.988365607365267e-13 W = 2.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x = torch.tensor([1, 2, 3, 4], dtype=torch.float32)  #Input\n",
    "y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)  #Output théorique\n",
    "\n",
    "W = torch.rand(1, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "\n",
    "    def __init__(self, W):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.W = nn.Parameter(W, requires_grad=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.W * x\n",
    "\n",
    "model = MyModel(W=W)\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iters = 400\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # Prediction\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # loss\n",
    "    l = loss(y_pred, y)\n",
    "\n",
    "    # backward pass\n",
    "    l.backward()\n",
    "\n",
    "    #update weights\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    print(f\"epoch {epoch}/{n_iters} loss {l} W = {(W[0]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We converge to the correct value. Wonderful! Let's complexify our previous equation by using matrix. We now have :\n",
    "\n",
    "$\\mathbf{y} = \\mathbf{W} * \\vec{x}$ with $\\mathbf{W} = [[1, 2],[3, 4]]$\n",
    "\n",
    "$\\vec{x}$ is therefore a 2x1 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W tensor([[ 0.7389, -0.3510],\n",
      "        [-0.8049,  0.4715]])\n",
      "epoch 0/500 loss 60.98081588745117\n",
      "epoch 1/500 loss 56.493003845214844\n",
      "epoch 2/500 loss 52.335472106933594\n",
      "epoch 3/500 loss 48.483909606933594\n",
      "epoch 4/500 loss 44.91579818725586\n",
      "epoch 5/500 loss 41.61027526855469\n",
      "epoch 6/500 loss 38.54801559448242\n",
      "epoch 7/500 loss 35.711124420166016\n",
      "epoch 8/500 loss 33.083011627197266\n",
      "epoch 9/500 loss 30.648305892944336\n",
      "epoch 10/500 loss 28.392784118652344\n",
      "epoch 11/500 loss 26.303253173828125\n",
      "epoch 12/500 loss 24.367496490478516\n",
      "epoch 13/500 loss 22.574201583862305\n",
      "epoch 14/500 loss 20.912879943847656\n",
      "epoch 15/500 loss 19.373823165893555\n",
      "epoch 16/500 loss 17.94803237915039\n",
      "epoch 17/500 loss 16.62717056274414\n",
      "epoch 18/500 loss 15.403512954711914\n",
      "epoch 19/500 loss 14.269912719726562\n",
      "epoch 20/500 loss 13.219734191894531\n",
      "epoch 21/500 loss 12.246845245361328\n",
      "epoch 22/500 loss 11.34555435180664\n",
      "epoch 23/500 loss 10.51059341430664\n",
      "epoch 24/500 loss 9.737080574035645\n",
      "epoch 25/500 loss 9.020492553710938\n",
      "epoch 26/500 loss 8.356640815734863\n",
      "epoch 27/500 loss 7.741644859313965\n",
      "epoch 28/500 loss 7.171907901763916\n",
      "epoch 29/500 loss 6.644099712371826\n",
      "epoch 30/500 loss 6.1551361083984375\n",
      "epoch 31/500 loss 5.702156066894531\n",
      "epoch 32/500 loss 5.282512664794922\n",
      "epoch 33/500 loss 4.8937530517578125\n",
      "epoch 34/500 loss 4.533603668212891\n",
      "epoch 35/500 loss 4.199958324432373\n",
      "epoch 36/500 loss 3.8908681869506836\n",
      "epoch 37/500 loss 3.6045241355895996\n",
      "epoch 38/500 loss 3.3392529487609863\n",
      "epoch 39/500 loss 3.0935049057006836\n",
      "epoch 40/500 loss 2.8658416271209717\n",
      "epoch 41/500 loss 2.6549339294433594\n",
      "epoch 42/500 loss 2.459547519683838\n",
      "epoch 43/500 loss 2.2785401344299316\n",
      "epoch 44/500 loss 2.110853672027588\n",
      "epoch 45/500 loss 1.9555081129074097\n",
      "epoch 46/500 loss 1.8115947246551514\n",
      "epoch 47/500 loss 1.6782723665237427\n",
      "epoch 48/500 loss 1.5547621250152588\n",
      "epoch 49/500 loss 1.4403412342071533\n",
      "epoch 50/500 loss 1.3343414068222046\n",
      "epoch 51/500 loss 1.2361421585083008\n",
      "epoch 52/500 loss 1.1451698541641235\n",
      "epoch 53/500 loss 1.0608925819396973\n",
      "epoch 54/500 loss 0.9828173518180847\n",
      "epoch 55/500 loss 0.9104878306388855\n",
      "epoch 56/500 loss 0.8434817790985107\n",
      "epoch 57/500 loss 0.7814067602157593\n",
      "epoch 58/500 loss 0.7239000201225281\n",
      "epoch 59/500 loss 0.6706256866455078\n",
      "epoch 60/500 loss 0.6212720274925232\n",
      "epoch 61/500 loss 0.5755503177642822\n",
      "epoch 62/500 loss 0.5331933498382568\n",
      "epoch 63/500 loss 0.4939537048339844\n",
      "epoch 64/500 loss 0.45760202407836914\n",
      "epoch 65/500 loss 0.42392539978027344\n",
      "epoch 66/500 loss 0.392727255821228\n",
      "epoch 67/500 loss 0.36382487416267395\n",
      "epoch 68/500 loss 0.3370494842529297\n",
      "epoch 69/500 loss 0.3122449815273285\n",
      "epoch 70/500 loss 0.2892656624317169\n",
      "epoch 71/500 loss 0.2679774761199951\n",
      "epoch 72/500 loss 0.24825599789619446\n",
      "epoch 73/500 loss 0.229985773563385\n",
      "epoch 74/500 loss 0.2130601704120636\n",
      "epoch 75/500 loss 0.19738027453422546\n",
      "epoch 76/500 loss 0.18285422027111053\n",
      "epoch 77/500 loss 0.1693972647190094\n",
      "epoch 78/500 loss 0.15693069994449615\n",
      "epoch 79/500 loss 0.1453816294670105\n",
      "epoch 80/500 loss 0.13468250632286072\n",
      "epoch 81/500 loss 0.12477071583271027\n",
      "epoch 82/500 loss 0.11558839678764343\n",
      "epoch 83/500 loss 0.10708178579807281\n",
      "epoch 84/500 loss 0.09920135885477066\n",
      "epoch 85/500 loss 0.09190075844526291\n",
      "epoch 86/500 loss 0.08513735979795456\n",
      "epoch 87/500 loss 0.07887185364961624\n",
      "epoch 88/500 loss 0.07306742668151855\n",
      "epoch 89/500 loss 0.06769005209207535\n",
      "epoch 90/500 loss 0.06270840764045715\n",
      "epoch 91/500 loss 0.058093518018722534\n",
      "epoch 92/500 loss 0.053818199783563614\n",
      "epoch 93/500 loss 0.04985753446817398\n",
      "epoch 94/500 loss 0.046188343316316605\n",
      "epoch 95/500 loss 0.042789191007614136\n",
      "epoch 96/500 loss 0.039640143513679504\n",
      "epoch 97/500 loss 0.03672289103269577\n",
      "epoch 98/500 loss 0.03402034193277359\n",
      "epoch 99/500 loss 0.031516652554273605\n",
      "epoch 100/500 loss 0.029197268187999725\n",
      "epoch 101/500 loss 0.027048537507653236\n",
      "epoch 102/500 loss 0.025057964026927948\n",
      "epoch 103/500 loss 0.023213881999254227\n",
      "epoch 104/500 loss 0.02150554209947586\n",
      "epoch 105/500 loss 0.019922884181141853\n",
      "epoch 106/500 loss 0.01845671236515045\n",
      "epoch 107/500 loss 0.017098387703299522\n",
      "epoch 108/500 loss 0.01584005542099476\n",
      "epoch 109/500 loss 0.014674345031380653\n",
      "epoch 110/500 loss 0.013594400137662888\n",
      "epoch 111/500 loss 0.012593983672559261\n",
      "epoch 112/500 loss 0.01166714821010828\n",
      "epoch 113/500 loss 0.010808517225086689\n",
      "epoch 114/500 loss 0.010013073682785034\n",
      "epoch 115/500 loss 0.009276140481233597\n",
      "epoch 116/500 loss 0.008593488484621048\n",
      "epoch 117/500 loss 0.007961089722812176\n",
      "epoch 118/500 loss 0.007375197019428015\n",
      "epoch 119/500 loss 0.006832441780716181\n",
      "epoch 120/500 loss 0.006329583004117012\n",
      "epoch 121/500 loss 0.005863779224455357\n",
      "epoch 122/500 loss 0.005432271398603916\n",
      "epoch 123/500 loss 0.005032504443079233\n",
      "epoch 124/500 loss 0.004662133753299713\n",
      "epoch 125/500 loss 0.004319000989198685\n",
      "epoch 126/500 loss 0.004001127555966377\n",
      "epoch 127/500 loss 0.0037066445220261812\n",
      "epoch 128/500 loss 0.0034338603727519512\n",
      "epoch 129/500 loss 0.0031811343505978584\n",
      "epoch 130/500 loss 0.0029470371082425117\n",
      "epoch 131/500 loss 0.002730170264840126\n",
      "epoch 132/500 loss 0.0025292658247053623\n",
      "epoch 133/500 loss 0.002343137515708804\n",
      "epoch 134/500 loss 0.002170693129301071\n",
      "epoch 135/500 loss 0.0020109452307224274\n",
      "epoch 136/500 loss 0.0018629446858540177\n",
      "epoch 137/500 loss 0.0017258299048990011\n",
      "epoch 138/500 loss 0.001598825678229332\n",
      "epoch 139/500 loss 0.0014811609871685505\n",
      "epoch 140/500 loss 0.0013721652794629335\n",
      "epoch 141/500 loss 0.001271175453439355\n",
      "epoch 142/500 loss 0.0011776298051699996\n",
      "epoch 143/500 loss 0.0010909605771303177\n",
      "epoch 144/500 loss 0.0010106852278113365\n",
      "epoch 145/500 loss 0.0009363093413412571\n",
      "epoch 146/500 loss 0.0008674047421664\n",
      "epoch 147/500 loss 0.0008035702630877495\n",
      "epoch 148/500 loss 0.0007444350048899651\n",
      "epoch 149/500 loss 0.000689652340952307\n",
      "epoch 150/500 loss 0.0006388938054442406\n",
      "epoch 151/500 loss 0.0005918791284784675\n",
      "epoch 152/500 loss 0.0005483247805386782\n",
      "epoch 153/500 loss 0.0005079684779047966\n",
      "epoch 154/500 loss 0.00047059045755304396\n",
      "epoch 155/500 loss 0.0004359573940746486\n",
      "epoch 156/500 loss 0.00040387629996985197\n",
      "epoch 157/500 loss 0.0003741568070836365\n",
      "epoch 158/500 loss 0.00034662449616007507\n",
      "epoch 159/500 loss 0.00032111399923451245\n",
      "epoch 160/500 loss 0.00029748203814961016\n",
      "epoch 161/500 loss 0.0002755870809778571\n",
      "epoch 162/500 loss 0.00025530741550028324\n",
      "epoch 163/500 loss 0.00023651227820664644\n",
      "epoch 164/500 loss 0.000219102599658072\n",
      "epoch 165/500 loss 0.00020298098388593644\n",
      "epoch 166/500 loss 0.0001880460768006742\n",
      "epoch 167/500 loss 0.0001742021704558283\n",
      "epoch 168/500 loss 0.00016138081264216453\n",
      "epoch 169/500 loss 0.00014950089098419994\n",
      "epoch 170/500 loss 0.00013849734386894852\n",
      "epoch 171/500 loss 0.00012830650666728616\n",
      "epoch 172/500 loss 0.00011886353604495525\n",
      "epoch 173/500 loss 0.00011011272727046162\n",
      "epoch 174/500 loss 0.00010200982069363818\n",
      "epoch 175/500 loss 9.449956996832043e-05\n",
      "epoch 176/500 loss 8.754558075452223e-05\n",
      "epoch 177/500 loss 8.110252383630723e-05\n",
      "epoch 178/500 loss 7.51336629036814e-05\n",
      "epoch 179/500 loss 6.9605273893103e-05\n",
      "epoch 180/500 loss 6.448553176596761e-05\n",
      "epoch 181/500 loss 5.974023588350974e-05\n",
      "epoch 182/500 loss 5.5346652516163886e-05\n",
      "epoch 183/500 loss 5.127174881636165e-05\n",
      "epoch 184/500 loss 4.749714571516961e-05\n",
      "epoch 185/500 loss 4.40017793152947e-05\n",
      "epoch 186/500 loss 4.076616096426733e-05\n",
      "epoch 187/500 loss 3.776618905249052e-05\n",
      "epoch 188/500 loss 3.4986351238330826e-05\n",
      "epoch 189/500 loss 3.2413110602647066e-05\n",
      "epoch 190/500 loss 3.002729863510467e-05\n",
      "epoch 191/500 loss 2.7818987291539088e-05\n",
      "epoch 192/500 loss 2.57716492342297e-05\n",
      "epoch 193/500 loss 2.387488893873524e-05\n",
      "epoch 194/500 loss 2.2116768377600238e-05\n",
      "epoch 195/500 loss 2.049088834610302e-05\n",
      "epoch 196/500 loss 1.8982062101713382e-05\n",
      "epoch 197/500 loss 1.7583992303116247e-05\n",
      "epoch 198/500 loss 1.6290116036543623e-05\n",
      "epoch 199/500 loss 1.5091770364961121e-05\n",
      "epoch 200/500 loss 1.3981075426272582e-05\n",
      "epoch 201/500 loss 1.295148285862524e-05\n",
      "epoch 202/500 loss 1.199756752612302e-05\n",
      "epoch 203/500 loss 1.1113513210148085e-05\n",
      "epoch 204/500 loss 1.0294559615431353e-05\n",
      "epoch 205/500 loss 9.537060577713419e-06\n",
      "epoch 206/500 loss 8.835518201522063e-06\n",
      "epoch 207/500 loss 8.185318620235194e-06\n",
      "epoch 208/500 loss 7.583863407489844e-06\n",
      "epoch 209/500 loss 7.025072591204662e-06\n",
      "epoch 210/500 loss 6.508705155283678e-06\n",
      "epoch 211/500 loss 6.029206815583166e-06\n",
      "epoch 212/500 loss 5.586140105151571e-06\n",
      "epoch 213/500 loss 5.175387741473969e-06\n",
      "epoch 214/500 loss 4.794705091626383e-06\n",
      "epoch 215/500 loss 4.441480996320024e-06\n",
      "epoch 216/500 loss 4.1139082895824686e-06\n",
      "epoch 217/500 loss 3.8114087601570645e-06\n",
      "epoch 218/500 loss 3.530595677148085e-06\n",
      "epoch 219/500 loss 3.2705236208130373e-06\n",
      "epoch 220/500 loss 3.0297544526547426e-06\n",
      "epoch 221/500 loss 2.8067636321793543e-06\n",
      "epoch 222/500 loss 2.6005361632996937e-06\n",
      "epoch 223/500 loss 2.4086136818368686e-06\n",
      "epoch 224/500 loss 2.2311899101623567e-06\n",
      "epoch 225/500 loss 2.0670056528615532e-06\n",
      "epoch 226/500 loss 1.9151350443280535e-06\n",
      "epoch 227/500 loss 1.7744403066899395e-06\n",
      "epoch 228/500 loss 1.643883024371462e-06\n",
      "epoch 229/500 loss 1.5231671568471938e-06\n",
      "epoch 230/500 loss 1.4107361039350508e-06\n",
      "epoch 231/500 loss 1.3070571185380686e-06\n",
      "epoch 232/500 loss 1.2109682074878947e-06\n",
      "epoch 233/500 loss 1.1220395208511036e-06\n",
      "epoch 234/500 loss 1.0397010328233591e-06\n",
      "epoch 235/500 loss 9.632788078306476e-07\n",
      "epoch 236/500 loss 8.923787504500069e-07\n",
      "epoch 237/500 loss 8.26992788915959e-07\n",
      "epoch 238/500 loss 7.660586334168329e-07\n",
      "epoch 239/500 loss 7.097478942341695e-07\n",
      "epoch 240/500 loss 6.572580559804919e-07\n",
      "epoch 241/500 loss 6.086493158363737e-07\n",
      "epoch 242/500 loss 5.639640221488662e-07\n",
      "epoch 243/500 loss 5.225986114965053e-07\n",
      "epoch 244/500 loss 4.84196618799615e-07\n",
      "epoch 245/500 loss 4.488491924803384e-07\n",
      "epoch 246/500 loss 4.1577766296541085e-07\n",
      "epoch 247/500 loss 3.853736529890739e-07\n",
      "epoch 248/500 loss 3.5692181654667365e-07\n",
      "epoch 249/500 loss 3.306631128907611e-07\n",
      "epoch 250/500 loss 3.0631267122771533e-07\n",
      "epoch 251/500 loss 2.8406327601260273e-07\n",
      "epoch 252/500 loss 2.6305326628062176e-07\n",
      "epoch 253/500 loss 2.4383609797951067e-07\n",
      "epoch 254/500 loss 2.2584818282211927e-07\n",
      "epoch 255/500 loss 2.092260302788418e-07\n",
      "epoch 256/500 loss 1.938481801744274e-07\n",
      "epoch 257/500 loss 1.7954171482870152e-07\n",
      "epoch 258/500 loss 1.6647091172217188e-07\n",
      "epoch 259/500 loss 1.5418396515087807e-07\n",
      "epoch 260/500 loss 1.4289642535914027e-07\n",
      "epoch 261/500 loss 1.3232501316906564e-07\n",
      "epoch 262/500 loss 1.2254875514372543e-07\n",
      "epoch 263/500 loss 1.1349200690347061e-07\n",
      "epoch 264/500 loss 1.0507448422458765e-07\n",
      "epoch 265/500 loss 9.731527939038642e-08\n",
      "epoch 266/500 loss 9.016058299948781e-08\n",
      "epoch 267/500 loss 8.36010656257713e-08\n",
      "epoch 268/500 loss 7.743301466689445e-08\n",
      "epoch 269/500 loss 7.175670191372774e-08\n",
      "epoch 270/500 loss 6.643431049724313e-08\n",
      "epoch 271/500 loss 6.154537857128162e-08\n",
      "epoch 272/500 loss 5.6995393293846064e-08\n",
      "epoch 273/500 loss 5.27890762214156e-08\n",
      "epoch 274/500 loss 4.890142335511882e-08\n",
      "epoch 275/500 loss 4.5270304838140873e-08\n",
      "epoch 276/500 loss 4.197874758915532e-08\n",
      "epoch 277/500 loss 3.8850082262342767e-08\n",
      "epoch 278/500 loss 3.59880800715473e-08\n",
      "epoch 279/500 loss 3.336218767913124e-08\n",
      "epoch 280/500 loss 3.089753164431386e-08\n",
      "epoch 281/500 loss 2.8702977772354643e-08\n",
      "epoch 282/500 loss 2.6585983192717322e-08\n",
      "epoch 283/500 loss 2.4648842966712436e-08\n",
      "epoch 284/500 loss 2.2819975242782675e-08\n",
      "epoch 285/500 loss 2.1114367143582058e-08\n",
      "epoch 286/500 loss 1.957927153739547e-08\n",
      "epoch 287/500 loss 1.8116921296496002e-08\n",
      "epoch 288/500 loss 1.6794253099305934e-08\n",
      "epoch 289/500 loss 1.5553688115232944e-08\n",
      "epoch 290/500 loss 1.4381623891779327e-08\n",
      "epoch 291/500 loss 1.332696530909061e-08\n",
      "epoch 292/500 loss 1.2343801536474075e-08\n",
      "epoch 293/500 loss 1.1411455780319102e-08\n",
      "epoch 294/500 loss 1.0567854147325306e-08\n",
      "epoch 295/500 loss 9.778873710786229e-09\n",
      "epoch 296/500 loss 9.055143301850421e-09\n",
      "epoch 297/500 loss 8.382433414055868e-09\n",
      "epoch 298/500 loss 7.77587505496058e-09\n",
      "epoch 299/500 loss 7.2182118060482026e-09\n",
      "epoch 300/500 loss 6.69296884581172e-09\n",
      "epoch 301/500 loss 6.214236236701254e-09\n",
      "epoch 302/500 loss 5.727874174965564e-09\n",
      "epoch 303/500 loss 5.328609553600927e-09\n",
      "epoch 304/500 loss 4.920246432504882e-09\n",
      "epoch 305/500 loss 4.569258749143046e-09\n",
      "epoch 306/500 loss 4.232941996917816e-09\n",
      "epoch 307/500 loss 3.9061411882812536e-09\n",
      "epoch 308/500 loss 3.6322074237205015e-09\n",
      "epoch 309/500 loss 3.3462781434678845e-09\n",
      "epoch 310/500 loss 3.1293980740088045e-09\n",
      "epoch 311/500 loss 2.888691286173639e-09\n",
      "epoch 312/500 loss 2.6923618889895806e-09\n",
      "epoch 313/500 loss 2.469622062406529e-09\n",
      "epoch 314/500 loss 2.290943434957171e-09\n",
      "epoch 315/500 loss 2.1059840538129038e-09\n",
      "epoch 316/500 loss 1.9580115306894186e-09\n",
      "epoch 317/500 loss 1.820862793877609e-09\n",
      "epoch 318/500 loss 1.6892016674319166e-09\n",
      "epoch 319/500 loss 1.5688830234950046e-09\n",
      "epoch 320/500 loss 1.4463781283780008e-09\n",
      "epoch 321/500 loss 1.3353258498938203e-09\n",
      "epoch 322/500 loss 1.2338121635480093e-09\n",
      "epoch 323/500 loss 1.144001560149377e-09\n",
      "epoch 324/500 loss 1.0594920496487248e-09\n",
      "epoch 325/500 loss 9.92728788062891e-10\n",
      "epoch 326/500 loss 9.28193522042875e-10\n",
      "epoch 327/500 loss 8.661136252641199e-10\n",
      "epoch 328/500 loss 8.047411625966561e-10\n",
      "epoch 329/500 loss 7.467868545774081e-10\n",
      "epoch 330/500 loss 6.91170010114206e-10\n",
      "epoch 331/500 loss 6.403235719432132e-10\n",
      "epoch 332/500 loss 5.927953683482201e-10\n",
      "epoch 333/500 loss 5.454874330013126e-10\n",
      "epoch 334/500 loss 5.014124671021136e-10\n",
      "epoch 335/500 loss 4.5832515560562115e-10\n",
      "epoch 336/500 loss 4.183855484285459e-10\n",
      "epoch 337/500 loss 3.8740943786308435e-10\n",
      "epoch 338/500 loss 3.558080496901539e-10\n",
      "epoch 339/500 loss 3.3627522988410874e-10\n",
      "epoch 340/500 loss 3.18142179267511e-10\n",
      "epoch 341/500 loss 2.9677615920320477e-10\n",
      "epoch 342/500 loss 2.799647180751208e-10\n",
      "epoch 343/500 loss 2.600055726276196e-10\n",
      "epoch 344/500 loss 2.430156076371759e-10\n",
      "epoch 345/500 loss 2.2984303349460333e-10\n",
      "epoch 346/500 loss 2.1389401361204818e-10\n",
      "epoch 347/500 loss 2.0098078756802806e-10\n",
      "epoch 348/500 loss 1.8904278142883868e-10\n",
      "epoch 349/500 loss 1.7461254664397075e-10\n",
      "epoch 350/500 loss 1.629907320221946e-10\n",
      "epoch 351/500 loss 1.4962986405464562e-10\n",
      "epoch 352/500 loss 1.3686052291461692e-10\n",
      "epoch 353/500 loss 1.2705592133954724e-10\n",
      "epoch 354/500 loss 1.1532752530740709e-10\n",
      "epoch 355/500 loss 1.0595280208747226e-10\n",
      "epoch 356/500 loss 9.738276851578576e-11\n",
      "epoch 357/500 loss 8.717315758133282e-11\n",
      "epoch 358/500 loss 7.908984578364198e-11\n",
      "epoch 359/500 loss 6.994960166650799e-11\n",
      "epoch 360/500 loss 6.140088437689428e-11\n",
      "epoch 361/500 loss 5.4964255369327475e-11\n",
      "epoch 362/500 loss 5.040168282732793e-11\n",
      "epoch 363/500 loss 4.724776125897279e-11\n",
      "epoch 364/500 loss 4.655764662686579e-11\n",
      "epoch 365/500 loss 4.5521142411075743e-11\n",
      "epoch 366/500 loss 4.4550363398343507e-11\n",
      "epoch 367/500 loss 4.364530958866908e-11\n",
      "epoch 368/500 loss 4.280598098205246e-11\n",
      "epoch 369/500 loss 4.230238381808249e-11\n",
      "epoch 370/500 loss 4.230238381808249e-11\n",
      "epoch 371/500 loss 4.230238381808249e-11\n",
      "epoch 372/500 loss 4.230238381808249e-11\n",
      "epoch 373/500 loss 4.230238381808249e-11\n",
      "epoch 374/500 loss 4.230238381808249e-11\n",
      "epoch 375/500 loss 4.230238381808249e-11\n",
      "epoch 376/500 loss 4.230238381808249e-11\n",
      "epoch 377/500 loss 4.230238381808249e-11\n",
      "epoch 378/500 loss 4.230238381808249e-11\n",
      "epoch 379/500 loss 4.230238381808249e-11\n",
      "epoch 380/500 loss 4.230238381808249e-11\n",
      "epoch 381/500 loss 4.230238381808249e-11\n",
      "epoch 382/500 loss 4.230238381808249e-11\n",
      "epoch 383/500 loss 4.230238381808249e-11\n",
      "epoch 384/500 loss 4.230238381808249e-11\n",
      "epoch 385/500 loss 4.230238381808249e-11\n",
      "epoch 386/500 loss 4.230238381808249e-11\n",
      "epoch 387/500 loss 4.230238381808249e-11\n",
      "epoch 388/500 loss 4.230238381808249e-11\n",
      "epoch 389/500 loss 4.230238381808249e-11\n",
      "epoch 390/500 loss 4.230238381808249e-11\n",
      "epoch 391/500 loss 4.230238381808249e-11\n",
      "epoch 392/500 loss 4.230238381808249e-11\n",
      "epoch 393/500 loss 4.230238381808249e-11\n",
      "epoch 394/500 loss 4.230238381808249e-11\n",
      "epoch 395/500 loss 4.230238381808249e-11\n",
      "epoch 396/500 loss 4.230238381808249e-11\n",
      "epoch 397/500 loss 4.230238381808249e-11\n",
      "epoch 398/500 loss 4.230238381808249e-11\n",
      "epoch 399/500 loss 4.230238381808249e-11\n",
      "epoch 400/500 loss 4.230238381808249e-11\n",
      "epoch 401/500 loss 4.230238381808249e-11\n",
      "epoch 402/500 loss 4.230238381808249e-11\n",
      "epoch 403/500 loss 4.230238381808249e-11\n",
      "epoch 404/500 loss 4.230238381808249e-11\n",
      "epoch 405/500 loss 4.230238381808249e-11\n",
      "epoch 406/500 loss 4.230238381808249e-11\n",
      "epoch 407/500 loss 4.230238381808249e-11\n",
      "epoch 408/500 loss 4.230238381808249e-11\n",
      "epoch 409/500 loss 4.230238381808249e-11\n",
      "epoch 410/500 loss 4.230238381808249e-11\n",
      "epoch 411/500 loss 4.230238381808249e-11\n",
      "epoch 412/500 loss 4.230238381808249e-11\n",
      "epoch 413/500 loss 4.230238381808249e-11\n",
      "epoch 414/500 loss 4.230238381808249e-11\n",
      "epoch 415/500 loss 4.230238381808249e-11\n",
      "epoch 416/500 loss 4.230238381808249e-11\n",
      "epoch 417/500 loss 4.230238381808249e-11\n",
      "epoch 418/500 loss 4.230238381808249e-11\n",
      "epoch 419/500 loss 4.230238381808249e-11\n",
      "epoch 420/500 loss 4.230238381808249e-11\n",
      "epoch 421/500 loss 4.230238381808249e-11\n",
      "epoch 422/500 loss 4.230238381808249e-11\n",
      "epoch 423/500 loss 4.230238381808249e-11\n",
      "epoch 424/500 loss 4.230238381808249e-11\n",
      "epoch 425/500 loss 4.230238381808249e-11\n",
      "epoch 426/500 loss 4.230238381808249e-11\n",
      "epoch 427/500 loss 4.230238381808249e-11\n",
      "epoch 428/500 loss 4.230238381808249e-11\n",
      "epoch 429/500 loss 4.230238381808249e-11\n",
      "epoch 430/500 loss 4.230238381808249e-11\n",
      "epoch 431/500 loss 4.230238381808249e-11\n",
      "epoch 432/500 loss 4.230238381808249e-11\n",
      "epoch 433/500 loss 4.230238381808249e-11\n",
      "epoch 434/500 loss 4.230238381808249e-11\n",
      "epoch 435/500 loss 4.230238381808249e-11\n",
      "epoch 436/500 loss 4.230238381808249e-11\n",
      "epoch 437/500 loss 4.230238381808249e-11\n",
      "epoch 438/500 loss 4.230238381808249e-11\n",
      "epoch 439/500 loss 4.230238381808249e-11\n",
      "epoch 440/500 loss 4.230238381808249e-11\n",
      "epoch 441/500 loss 4.230238381808249e-11\n",
      "epoch 442/500 loss 4.230238381808249e-11\n",
      "epoch 443/500 loss 4.230238381808249e-11\n",
      "epoch 444/500 loss 4.230238381808249e-11\n",
      "epoch 445/500 loss 4.230238381808249e-11\n",
      "epoch 446/500 loss 4.230238381808249e-11\n",
      "epoch 447/500 loss 4.230238381808249e-11\n",
      "epoch 448/500 loss 4.230238381808249e-11\n",
      "epoch 449/500 loss 4.230238381808249e-11\n",
      "epoch 450/500 loss 4.230238381808249e-11\n",
      "epoch 451/500 loss 4.230238381808249e-11\n",
      "epoch 452/500 loss 4.230238381808249e-11\n",
      "epoch 453/500 loss 4.230238381808249e-11\n",
      "epoch 454/500 loss 4.230238381808249e-11\n",
      "epoch 455/500 loss 4.230238381808249e-11\n",
      "epoch 456/500 loss 4.230238381808249e-11\n",
      "epoch 457/500 loss 4.230238381808249e-11\n",
      "epoch 458/500 loss 4.230238381808249e-11\n",
      "epoch 459/500 loss 4.230238381808249e-11\n",
      "epoch 460/500 loss 4.230238381808249e-11\n",
      "epoch 461/500 loss 4.230238381808249e-11\n",
      "epoch 462/500 loss 4.230238381808249e-11\n",
      "epoch 463/500 loss 4.230238381808249e-11\n",
      "epoch 464/500 loss 4.230238381808249e-11\n",
      "epoch 465/500 loss 4.230238381808249e-11\n",
      "epoch 466/500 loss 4.230238381808249e-11\n",
      "epoch 467/500 loss 4.230238381808249e-11\n",
      "epoch 468/500 loss 4.230238381808249e-11\n",
      "epoch 469/500 loss 4.230238381808249e-11\n",
      "epoch 470/500 loss 4.230238381808249e-11\n",
      "epoch 471/500 loss 4.230238381808249e-11\n",
      "epoch 472/500 loss 4.230238381808249e-11\n",
      "epoch 473/500 loss 4.230238381808249e-11\n",
      "epoch 474/500 loss 4.230238381808249e-11\n",
      "epoch 475/500 loss 4.230238381808249e-11\n",
      "epoch 476/500 loss 4.230238381808249e-11\n",
      "epoch 477/500 loss 4.230238381808249e-11\n",
      "epoch 478/500 loss 4.230238381808249e-11\n",
      "epoch 479/500 loss 4.230238381808249e-11\n",
      "epoch 480/500 loss 4.230238381808249e-11\n",
      "epoch 481/500 loss 4.230238381808249e-11\n",
      "epoch 482/500 loss 4.230238381808249e-11\n",
      "epoch 483/500 loss 4.230238381808249e-11\n",
      "epoch 484/500 loss 4.230238381808249e-11\n",
      "epoch 485/500 loss 4.230238381808249e-11\n",
      "epoch 486/500 loss 4.230238381808249e-11\n",
      "epoch 487/500 loss 4.230238381808249e-11\n",
      "epoch 488/500 loss 4.230238381808249e-11\n",
      "epoch 489/500 loss 4.230238381808249e-11\n",
      "epoch 490/500 loss 4.230238381808249e-11\n",
      "epoch 491/500 loss 4.230238381808249e-11\n",
      "epoch 492/500 loss 4.230238381808249e-11\n",
      "epoch 493/500 loss 4.230238381808249e-11\n",
      "epoch 494/500 loss 4.230238381808249e-11\n",
      "epoch 495/500 loss 4.230238381808249e-11\n",
      "epoch 496/500 loss 4.230238381808249e-11\n",
      "epoch 497/500 loss 4.230238381808249e-11\n",
      "epoch 498/500 loss 4.230238381808249e-11\n",
      "epoch 499/500 loss 4.230238381808249e-11\n",
      "Parameter containing:\n",
      "tensor([[1.0000, 2.0000],\n",
      "        [3.0000, 4.0000]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "x = torch.tensor([[[1],[1]], [[2],[2]], [[3],[3]], [[4],[4]]], dtype=torch.float32)\n",
    "\n",
    "W_true = torch.tensor([[1, 2], [3, 4]])\n",
    "\n",
    "W = (torch.randn(2, 2, dtype=torch.float32, requires_grad=True))\n",
    "W = nn.Parameter(W)\n",
    "\n",
    "y = W_true * x\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "\n",
    "    def __init__(self, W):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.W = W\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.W * x\n",
    "\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = MyModel(W=W)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "for name, param in model.named_parameters():  # To see params\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data)\n",
    "\n",
    "n_iters = 500\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    #Forward pass\n",
    "    y_pred = model(x)\n",
    "\n",
    "    #loss\n",
    "    l = loss(y_pred, y)\n",
    "\n",
    "    #Gradient\n",
    "    l.backward()\n",
    "\n",
    "    #update weights\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    print(f\"epoch {epoch}/{n_iters} loss {l}\")\n",
    "\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our matrix converge to the correct value! Let's now complexify our model by using a common matrix multiplication\n",
    "\n",
    "$\\vec{y} = \\mathbf{W}\\vec{x}$\n",
    "\n",
    "Let's begin by generating our fake data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.linspace(0, 5, 10)\n",
    "x2 = np.linspace(2, 8, 10)\n",
    "\n",
    "X = np.array([x1, x2]).T\n",
    "\n",
    "W_true = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "y = np.zeros((X.shape[0], X.shape[1]))\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    y[i] = W_true @ X[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\AppData\\Local\\Temp/ipykernel_8872/564477219.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  W_true = torch.tensor(W_true, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1000 loss 1179.44189453125\n",
      "Epoch 1/1000 loss 465.47930908203125\n",
      "Epoch 2/1000 loss 183.80514526367188\n",
      "Epoch 3/1000 loss 72.67784881591797\n",
      "Epoch 4/1000 loss 28.83489418029785\n",
      "Epoch 5/1000 loss 11.537043571472168\n",
      "Epoch 6/1000 loss 4.711792469024658\n",
      "Epoch 7/1000 loss 2.0182104110717773\n",
      "Epoch 8/1000 loss 0.95466548204422\n",
      "Epoch 9/1000 loss 0.5342071056365967\n",
      "Epoch 10/1000 loss 0.36746522784233093\n",
      "Epoch 11/1000 loss 0.30082470178604126\n",
      "Epoch 12/1000 loss 0.2736814320087433\n",
      "Epoch 13/1000 loss 0.2621247172355652\n",
      "Epoch 14/1000 loss 0.2567223608493805\n",
      "Epoch 15/1000 loss 0.2537519931793213\n",
      "Epoch 16/1000 loss 0.251746267080307\n",
      "Epoch 17/1000 loss 0.250125914812088\n",
      "Epoch 18/1000 loss 0.2486613690853119\n",
      "Epoch 19/1000 loss 0.24726340174674988\n",
      "Epoch 20/1000 loss 0.24589622020721436\n",
      "Epoch 21/1000 loss 0.24454502761363983\n",
      "Epoch 22/1000 loss 0.2432052195072174\n",
      "Epoch 23/1000 loss 0.2418738603591919\n",
      "Epoch 24/1000 loss 0.24055016040802002\n",
      "Epoch 25/1000 loss 0.23923425376415253\n",
      "Epoch 26/1000 loss 0.2379254847764969\n",
      "Epoch 27/1000 loss 0.2366243153810501\n",
      "Epoch 28/1000 loss 0.23532970249652863\n",
      "Epoch 29/1000 loss 0.23404252529144287\n",
      "Epoch 30/1000 loss 0.23276257514953613\n",
      "Epoch 31/1000 loss 0.23148906230926514\n",
      "Epoch 32/1000 loss 0.23022308945655823\n",
      "Epoch 33/1000 loss 0.22896401584148407\n",
      "Epoch 34/1000 loss 0.2277112901210785\n",
      "Epoch 35/1000 loss 0.2264658510684967\n",
      "Epoch 36/1000 loss 0.22522707283496857\n",
      "Epoch 37/1000 loss 0.22399485111236572\n",
      "Epoch 38/1000 loss 0.22276976704597473\n",
      "Epoch 39/1000 loss 0.2215513437986374\n",
      "Epoch 40/1000 loss 0.22033897042274475\n",
      "Epoch 41/1000 loss 0.21913404762744904\n",
      "Epoch 42/1000 loss 0.21793493628501892\n",
      "Epoch 43/1000 loss 0.21674314141273499\n",
      "Epoch 44/1000 loss 0.2155575305223465\n",
      "Epoch 45/1000 loss 0.2143784761428833\n",
      "Epoch 46/1000 loss 0.21320554614067078\n",
      "Epoch 47/1000 loss 0.2120397388935089\n",
      "Epoch 48/1000 loss 0.2108795940876007\n",
      "Epoch 49/1000 loss 0.209726020693779\n",
      "Epoch 50/1000 loss 0.20857898890972137\n",
      "Epoch 51/1000 loss 0.2074379175901413\n",
      "Epoch 52/1000 loss 0.20630331337451935\n",
      "Epoch 53/1000 loss 0.20517463982105255\n",
      "Epoch 54/1000 loss 0.20405273139476776\n",
      "Epoch 55/1000 loss 0.2029362916946411\n",
      "Epoch 56/1000 loss 0.20182621479034424\n",
      "Epoch 57/1000 loss 0.2007226198911667\n",
      "Epoch 58/1000 loss 0.1996242105960846\n",
      "Epoch 59/1000 loss 0.19853243231773376\n",
      "Epoch 60/1000 loss 0.1974463313817978\n",
      "Epoch 61/1000 loss 0.19636663794517517\n",
      "Epoch 62/1000 loss 0.19529233872890472\n",
      "Epoch 63/1000 loss 0.19422414898872375\n",
      "Epoch 64/1000 loss 0.19316190481185913\n",
      "Epoch 65/1000 loss 0.1921047866344452\n",
      "Epoch 66/1000 loss 0.19105415046215057\n",
      "Epoch 67/1000 loss 0.19000914692878723\n",
      "Epoch 68/1000 loss 0.18896955251693726\n",
      "Epoch 69/1000 loss 0.1879359483718872\n",
      "Epoch 70/1000 loss 0.18690793216228485\n",
      "Epoch 71/1000 loss 0.18588559329509735\n",
      "Epoch 72/1000 loss 0.18486884236335754\n",
      "Epoch 73/1000 loss 0.18385764956474304\n",
      "Epoch 74/1000 loss 0.18285150825977325\n",
      "Epoch 75/1000 loss 0.18185144662857056\n",
      "Epoch 76/1000 loss 0.18085689842700958\n",
      "Epoch 77/1000 loss 0.17986749112606049\n",
      "Epoch 78/1000 loss 0.1788835972547531\n",
      "Epoch 79/1000 loss 0.17790541052818298\n",
      "Epoch 80/1000 loss 0.17693188786506653\n",
      "Epoch 81/1000 loss 0.17596429586410522\n",
      "Epoch 82/1000 loss 0.1750018447637558\n",
      "Epoch 83/1000 loss 0.1740446537733078\n",
      "Epoch 84/1000 loss 0.1730923056602478\n",
      "Epoch 85/1000 loss 0.172145813703537\n",
      "Epoch 86/1000 loss 0.17120414972305298\n",
      "Epoch 87/1000 loss 0.1702674776315689\n",
      "Epoch 88/1000 loss 0.16933642327785492\n",
      "Epoch 89/1000 loss 0.16840991377830505\n",
      "Epoch 90/1000 loss 0.16748866438865662\n",
      "Epoch 91/1000 loss 0.16657258570194244\n",
      "Epoch 92/1000 loss 0.16566118597984314\n",
      "Epoch 93/1000 loss 0.1647549569606781\n",
      "Epoch 94/1000 loss 0.1638539731502533\n",
      "Epoch 95/1000 loss 0.16295775771141052\n",
      "Epoch 96/1000 loss 0.16206622123718262\n",
      "Epoch 97/1000 loss 0.16117990016937256\n",
      "Epoch 98/1000 loss 0.16029810905456543\n",
      "Epoch 99/1000 loss 0.1594214141368866\n",
      "Epoch 100/1000 loss 0.1585494577884674\n",
      "Epoch 101/1000 loss 0.15768204629421234\n",
      "Epoch 102/1000 loss 0.1568196713924408\n",
      "Epoch 103/1000 loss 0.15596188604831696\n",
      "Epoch 104/1000 loss 0.15510866045951843\n",
      "Epoch 105/1000 loss 0.15426024794578552\n",
      "Epoch 106/1000 loss 0.15341638028621674\n",
      "Epoch 107/1000 loss 0.15257708728313446\n",
      "Epoch 108/1000 loss 0.15174268186092377\n",
      "Epoch 109/1000 loss 0.15091285109519958\n",
      "Epoch 110/1000 loss 0.1500871777534485\n",
      "Epoch 111/1000 loss 0.14926601946353912\n",
      "Epoch 112/1000 loss 0.14844973385334015\n",
      "Epoch 113/1000 loss 0.14763754606246948\n",
      "Epoch 114/1000 loss 0.1468299925327301\n",
      "Epoch 115/1000 loss 0.14602690935134888\n",
      "Epoch 116/1000 loss 0.1452280580997467\n",
      "Epoch 117/1000 loss 0.1444336622953415\n",
      "Epoch 118/1000 loss 0.14364348351955414\n",
      "Epoch 119/1000 loss 0.1428578644990921\n",
      "Epoch 120/1000 loss 0.14207667112350464\n",
      "Epoch 121/1000 loss 0.1412992775440216\n",
      "Epoch 122/1000 loss 0.1405264288187027\n",
      "Epoch 123/1000 loss 0.13975781202316284\n",
      "Epoch 124/1000 loss 0.13899332284927368\n",
      "Epoch 125/1000 loss 0.13823309540748596\n",
      "Epoch 126/1000 loss 0.13747669756412506\n",
      "Epoch 127/1000 loss 0.1367247849702835\n",
      "Epoch 128/1000 loss 0.13597701489925385\n",
      "Epoch 129/1000 loss 0.13523340225219727\n",
      "Epoch 130/1000 loss 0.13449349999427795\n",
      "Epoch 131/1000 loss 0.13375785946846008\n",
      "Epoch 132/1000 loss 0.13302597403526306\n",
      "Epoch 133/1000 loss 0.1322985738515854\n",
      "Epoch 134/1000 loss 0.13157495856285095\n",
      "Epoch 135/1000 loss 0.13085518777370453\n",
      "Epoch 136/1000 loss 0.13013949990272522\n",
      "Epoch 137/1000 loss 0.12942735850811005\n",
      "Epoch 138/1000 loss 0.1287194788455963\n",
      "Epoch 139/1000 loss 0.128015398979187\n",
      "Epoch 140/1000 loss 0.12731525301933289\n",
      "Epoch 141/1000 loss 0.12661860883235931\n",
      "Epoch 142/1000 loss 0.1259261518716812\n",
      "Epoch 143/1000 loss 0.1252373605966568\n",
      "Epoch 144/1000 loss 0.12455222755670547\n",
      "Epoch 145/1000 loss 0.12387095391750336\n",
      "Epoch 146/1000 loss 0.12319345772266388\n",
      "Epoch 147/1000 loss 0.12251947820186615\n",
      "Epoch 148/1000 loss 0.12184921652078629\n",
      "Epoch 149/1000 loss 0.12118270248174667\n",
      "Epoch 150/1000 loss 0.12051986157894135\n",
      "Epoch 151/1000 loss 0.11986052989959717\n",
      "Epoch 152/1000 loss 0.11920485645532608\n",
      "Epoch 153/1000 loss 0.11855286359786987\n",
      "Epoch 154/1000 loss 0.11790456622838974\n",
      "Epoch 155/1000 loss 0.11725946515798569\n",
      "Epoch 156/1000 loss 0.1166180819272995\n",
      "Epoch 157/1000 loss 0.1159803718328476\n",
      "Epoch 158/1000 loss 0.11534587293863297\n",
      "Epoch 159/1000 loss 0.1147148460149765\n",
      "Epoch 160/1000 loss 0.11408740282058716\n",
      "Epoch 161/1000 loss 0.11346352100372314\n",
      "Epoch 162/1000 loss 0.11284299939870834\n",
      "Epoch 163/1000 loss 0.11222542822360992\n",
      "Epoch 164/1000 loss 0.11161158233880997\n",
      "Epoch 165/1000 loss 0.11100111901760101\n",
      "Epoch 166/1000 loss 0.11039378494024277\n",
      "Epoch 167/1000 loss 0.10979007184505463\n",
      "Epoch 168/1000 loss 0.10918940603733063\n",
      "Epoch 169/1000 loss 0.10859215259552002\n",
      "Epoch 170/1000 loss 0.10799820721149445\n",
      "Epoch 171/1000 loss 0.10740746557712555\n",
      "Epoch 172/1000 loss 0.10681988298892975\n",
      "Epoch 173/1000 loss 0.10623564571142197\n",
      "Epoch 174/1000 loss 0.10565458238124847\n",
      "Epoch 175/1000 loss 0.10507651418447495\n",
      "Epoch 176/1000 loss 0.10450178384780884\n",
      "Epoch 177/1000 loss 0.10393023490905762\n",
      "Epoch 178/1000 loss 0.10336177051067352\n",
      "Epoch 179/1000 loss 0.10279630124568939\n",
      "Epoch 180/1000 loss 0.10223390907049179\n",
      "Epoch 181/1000 loss 0.1016748771071434\n",
      "Epoch 182/1000 loss 0.10111856460571289\n",
      "Epoch 183/1000 loss 0.10056551545858383\n",
      "Epoch 184/1000 loss 0.10001548379659653\n",
      "Epoch 185/1000 loss 0.09946837276220322\n",
      "Epoch 186/1000 loss 0.0989244133234024\n",
      "Epoch 187/1000 loss 0.09838299453258514\n",
      "Epoch 188/1000 loss 0.0978449285030365\n",
      "Epoch 189/1000 loss 0.09730986505746841\n",
      "Epoch 190/1000 loss 0.09677732735872269\n",
      "Epoch 191/1000 loss 0.09624795615673065\n",
      "Epoch 192/1000 loss 0.09572179615497589\n",
      "Epoch 193/1000 loss 0.09519810229539871\n",
      "Epoch 194/1000 loss 0.09467718750238419\n",
      "Epoch 195/1000 loss 0.09415940940380096\n",
      "Epoch 196/1000 loss 0.09364418685436249\n",
      "Epoch 197/1000 loss 0.0931321233510971\n",
      "Epoch 198/1000 loss 0.09262274205684662\n",
      "Epoch 199/1000 loss 0.09211598336696625\n",
      "Epoch 200/1000 loss 0.09161210805177689\n",
      "Epoch 201/1000 loss 0.09111103415489197\n",
      "Epoch 202/1000 loss 0.0906127318739891\n",
      "Epoch 203/1000 loss 0.09011690318584442\n",
      "Epoch 204/1000 loss 0.08962419629096985\n",
      "Epoch 205/1000 loss 0.08913387358188629\n",
      "Epoch 206/1000 loss 0.0886462852358818\n",
      "Epoch 207/1000 loss 0.08816132694482803\n",
      "Epoch 208/1000 loss 0.08767914772033691\n",
      "Epoch 209/1000 loss 0.0871993750333786\n",
      "Epoch 210/1000 loss 0.08672266453504562\n",
      "Epoch 211/1000 loss 0.08624817430973053\n",
      "Epoch 212/1000 loss 0.0857764184474945\n",
      "Epoch 213/1000 loss 0.08530686795711517\n",
      "Epoch 214/1000 loss 0.08484037220478058\n",
      "Epoch 215/1000 loss 0.08437642455101013\n",
      "Epoch 216/1000 loss 0.08391493558883667\n",
      "Epoch 217/1000 loss 0.08345590531826019\n",
      "Epoch 218/1000 loss 0.08299949020147324\n",
      "Epoch 219/1000 loss 0.08254554867744446\n",
      "Epoch 220/1000 loss 0.08209383487701416\n",
      "Epoch 221/1000 loss 0.08164482563734055\n",
      "Epoch 222/1000 loss 0.08119818568229675\n",
      "Epoch 223/1000 loss 0.08075413852930069\n",
      "Epoch 224/1000 loss 0.0803123489022255\n",
      "Epoch 225/1000 loss 0.07987309992313385\n",
      "Epoch 226/1000 loss 0.07943612337112427\n",
      "Epoch 227/1000 loss 0.07900150120258331\n",
      "Epoch 228/1000 loss 0.0785694345831871\n",
      "Epoch 229/1000 loss 0.07813961803913116\n",
      "Epoch 230/1000 loss 0.07771211862564087\n",
      "Epoch 231/1000 loss 0.07728712260723114\n",
      "Epoch 232/1000 loss 0.07686440646648407\n",
      "Epoch 233/1000 loss 0.07644391804933548\n",
      "Epoch 234/1000 loss 0.07602580636739731\n",
      "Epoch 235/1000 loss 0.07560998201370239\n",
      "Epoch 236/1000 loss 0.07519631087779999\n",
      "Epoch 237/1000 loss 0.07478509843349457\n",
      "Epoch 238/1000 loss 0.07437579333782196\n",
      "Epoch 239/1000 loss 0.07396912574768066\n",
      "Epoch 240/1000 loss 0.07356447726488113\n",
      "Epoch 241/1000 loss 0.07316192984580994\n",
      "Epoch 242/1000 loss 0.0727616399526596\n",
      "Epoch 243/1000 loss 0.0723637118935585\n",
      "Epoch 244/1000 loss 0.0719679594039917\n",
      "Epoch 245/1000 loss 0.07157430797815323\n",
      "Epoch 246/1000 loss 0.07118282467126846\n",
      "Epoch 247/1000 loss 0.07079339772462845\n",
      "Epoch 248/1000 loss 0.0704062208533287\n",
      "Epoch 249/1000 loss 0.07002115249633789\n",
      "Epoch 250/1000 loss 0.06963832676410675\n",
      "Epoch 251/1000 loss 0.06925719976425171\n",
      "Epoch 252/1000 loss 0.06887829303741455\n",
      "Epoch 253/1000 loss 0.06850150227546692\n",
      "Epoch 254/1000 loss 0.0681268572807312\n",
      "Epoch 255/1000 loss 0.06775413453578949\n",
      "Epoch 256/1000 loss 0.06738357245922089\n",
      "Epoch 257/1000 loss 0.06701508909463882\n",
      "Epoch 258/1000 loss 0.06664843112230301\n",
      "Epoch 259/1000 loss 0.06628398597240448\n",
      "Epoch 260/1000 loss 0.06592123210430145\n",
      "Epoch 261/1000 loss 0.06556074321269989\n",
      "Epoch 262/1000 loss 0.06520199775695801\n",
      "Epoch 263/1000 loss 0.06484540551900864\n",
      "Epoch 264/1000 loss 0.0644906610250473\n",
      "Epoch 265/1000 loss 0.06413794308900833\n",
      "Epoch 266/1000 loss 0.06378717720508575\n",
      "Epoch 267/1000 loss 0.063438281416893\n",
      "Epoch 268/1000 loss 0.06309114396572113\n",
      "Epoch 269/1000 loss 0.06274604797363281\n",
      "Epoch 270/1000 loss 0.06240284442901611\n",
      "Epoch 271/1000 loss 0.062061481177806854\n",
      "Epoch 272/1000 loss 0.06172200292348862\n",
      "Epoch 273/1000 loss 0.06138433888554573\n",
      "Epoch 274/1000 loss 0.061048638075590134\n",
      "Epoch 275/1000 loss 0.06071462482213974\n",
      "Epoch 276/1000 loss 0.06038246676325798\n",
      "Epoch 277/1000 loss 0.060052238404750824\n",
      "Epoch 278/1000 loss 0.05972366780042648\n",
      "Epoch 279/1000 loss 0.059396930038928986\n",
      "Epoch 280/1000 loss 0.05907221883535385\n",
      "Epoch 281/1000 loss 0.05874894931912422\n",
      "Epoch 282/1000 loss 0.05842765420675278\n",
      "Epoch 283/1000 loss 0.05810808017849922\n",
      "Epoch 284/1000 loss 0.05779016762971878\n",
      "Epoch 285/1000 loss 0.05747406929731369\n",
      "Epoch 286/1000 loss 0.057159729301929474\n",
      "Epoch 287/1000 loss 0.056847017258405685\n",
      "Epoch 288/1000 loss 0.05653604865074158\n",
      "Epoch 289/1000 loss 0.05622688680887222\n",
      "Epoch 290/1000 loss 0.05591921880841255\n",
      "Epoch 291/1000 loss 0.055613309144973755\n",
      "Epoch 292/1000 loss 0.05530925467610359\n",
      "Epoch 293/1000 loss 0.05500660464167595\n",
      "Epoch 294/1000 loss 0.05470579117536545\n",
      "Epoch 295/1000 loss 0.054406631737947464\n",
      "Epoch 296/1000 loss 0.05410902947187424\n",
      "Epoch 297/1000 loss 0.05381298065185547\n",
      "Epoch 298/1000 loss 0.053518496453762054\n",
      "Epoch 299/1000 loss 0.05322582274675369\n",
      "Epoch 300/1000 loss 0.05293459817767143\n",
      "Epoch 301/1000 loss 0.05264521390199661\n",
      "Epoch 302/1000 loss 0.052357129752635956\n",
      "Epoch 303/1000 loss 0.052070826292037964\n",
      "Epoch 304/1000 loss 0.05178598687052727\n",
      "Epoch 305/1000 loss 0.05150254815816879\n",
      "Epoch 306/1000 loss 0.05122097209095955\n",
      "Epoch 307/1000 loss 0.050940655171871185\n",
      "Epoch 308/1000 loss 0.050662022083997726\n",
      "Epoch 309/1000 loss 0.050385020673274994\n",
      "Epoch 310/1000 loss 0.050109393894672394\n",
      "Epoch 311/1000 loss 0.049835190176963806\n",
      "Epoch 312/1000 loss 0.0495627298951149\n",
      "Epoch 313/1000 loss 0.049291688948869705\n",
      "Epoch 314/1000 loss 0.04902196303009987\n",
      "Epoch 315/1000 loss 0.04875382035970688\n",
      "Epoch 316/1000 loss 0.048487164080142975\n",
      "Epoch 317/1000 loss 0.048221927136182785\n",
      "Epoch 318/1000 loss 0.04795818775892258\n",
      "Epoch 319/1000 loss 0.04769579693675041\n",
      "Epoch 320/1000 loss 0.04743490368127823\n",
      "Epoch 321/1000 loss 0.047175418585538864\n",
      "Epoch 322/1000 loss 0.04691731929779053\n",
      "Epoch 323/1000 loss 0.04666079208254814\n",
      "Epoch 324/1000 loss 0.046405501663684845\n",
      "Epoch 325/1000 loss 0.04615160822868347\n",
      "Epoch 326/1000 loss 0.045899201184511185\n",
      "Epoch 327/1000 loss 0.045648254454135895\n",
      "Epoch 328/1000 loss 0.04539845138788223\n",
      "Epoch 329/1000 loss 0.04515011981129646\n",
      "Epoch 330/1000 loss 0.04490311071276665\n",
      "Epoch 331/1000 loss 0.044657543301582336\n",
      "Epoch 332/1000 loss 0.044413160532712936\n",
      "Epoch 333/1000 loss 0.04417034611105919\n",
      "Epoch 334/1000 loss 0.043928615748882294\n",
      "Epoch 335/1000 loss 0.04368836432695389\n",
      "Epoch 336/1000 loss 0.04344939440488815\n",
      "Epoch 337/1000 loss 0.04321170598268509\n",
      "Epoch 338/1000 loss 0.04297531768679619\n",
      "Epoch 339/1000 loss 0.04274033010005951\n",
      "Epoch 340/1000 loss 0.04250664263963699\n",
      "Epoch 341/1000 loss 0.04227403551340103\n",
      "Epoch 342/1000 loss 0.042042724788188934\n",
      "Epoch 343/1000 loss 0.041812825947999954\n",
      "Epoch 344/1000 loss 0.041584186255931854\n",
      "Epoch 345/1000 loss 0.04135676473379135\n",
      "Epoch 346/1000 loss 0.04113047197461128\n",
      "Epoch 347/1000 loss 0.040905434638261795\n",
      "Epoch 348/1000 loss 0.04068177193403244\n",
      "Epoch 349/1000 loss 0.040459245443344116\n",
      "Epoch 350/1000 loss 0.0402379184961319\n",
      "Epoch 351/1000 loss 0.040017932653427124\n",
      "Epoch 352/1000 loss 0.03979889675974846\n",
      "Epoch 353/1000 loss 0.03958127647638321\n",
      "Epoch 354/1000 loss 0.039364732801914215\n",
      "Epoch 355/1000 loss 0.039149463176727295\n",
      "Epoch 356/1000 loss 0.03893529623746872\n",
      "Epoch 357/1000 loss 0.03872234746813774\n",
      "Epoch 358/1000 loss 0.03851049393415451\n",
      "Epoch 359/1000 loss 0.03829975798726082\n",
      "Epoch 360/1000 loss 0.038090240210294724\n",
      "Epoch 361/1000 loss 0.03788195550441742\n",
      "Epoch 362/1000 loss 0.03767474740743637\n",
      "Epoch 363/1000 loss 0.03746866062283516\n",
      "Epoch 364/1000 loss 0.0372636616230011\n",
      "Epoch 365/1000 loss 0.037059955298900604\n",
      "Epoch 366/1000 loss 0.036857135593891144\n",
      "Epoch 367/1000 loss 0.03665561228990555\n",
      "Epoch 368/1000 loss 0.03645508363842964\n",
      "Epoch 369/1000 loss 0.0362556129693985\n",
      "Epoch 370/1000 loss 0.03605729341506958\n",
      "Epoch 371/1000 loss 0.03586012125015259\n",
      "Epoch 372/1000 loss 0.035663947463035583\n",
      "Epoch 373/1000 loss 0.035468939691782\n",
      "Epoch 374/1000 loss 0.035274747759103775\n",
      "Epoch 375/1000 loss 0.03508198633790016\n",
      "Epoch 376/1000 loss 0.03488998860120773\n",
      "Epoch 377/1000 loss 0.03469907492399216\n",
      "Epoch 378/1000 loss 0.03450927883386612\n",
      "Epoch 379/1000 loss 0.03432050347328186\n",
      "Epoch 380/1000 loss 0.03413284569978714\n",
      "Epoch 381/1000 loss 0.03394601494073868\n",
      "Epoch 382/1000 loss 0.033760376274585724\n",
      "Epoch 383/1000 loss 0.03357571363449097\n",
      "Epoch 384/1000 loss 0.03339212387800217\n",
      "Epoch 385/1000 loss 0.03320937603712082\n",
      "Epoch 386/1000 loss 0.03302765637636185\n",
      "Epoch 387/1000 loss 0.032847099006175995\n",
      "Epoch 388/1000 loss 0.03266751393675804\n",
      "Epoch 389/1000 loss 0.03248870000243187\n",
      "Epoch 390/1000 loss 0.03231101483106613\n",
      "Epoch 391/1000 loss 0.032134316861629486\n",
      "Epoch 392/1000 loss 0.03195846453309059\n",
      "Epoch 393/1000 loss 0.031783826649188995\n",
      "Epoch 394/1000 loss 0.03160993754863739\n",
      "Epoch 395/1000 loss 0.03143691644072533\n",
      "Epoch 396/1000 loss 0.03126519173383713\n",
      "Epoch 397/1000 loss 0.031093988567590714\n",
      "Epoch 398/1000 loss 0.03092389926314354\n",
      "Epoch 399/1000 loss 0.03075472079217434\n",
      "Epoch 400/1000 loss 0.030586594715714455\n",
      "Epoch 401/1000 loss 0.030419250950217247\n",
      "Epoch 402/1000 loss 0.030252769589424133\n",
      "Epoch 403/1000 loss 0.030087336897850037\n",
      "Epoch 404/1000 loss 0.02992280200123787\n",
      "Epoch 405/1000 loss 0.029759040102362633\n",
      "Epoch 406/1000 loss 0.029596244916319847\n",
      "Epoch 407/1000 loss 0.029434403404593468\n",
      "Epoch 408/1000 loss 0.029273424297571182\n",
      "Epoch 409/1000 loss 0.029113277792930603\n",
      "Epoch 410/1000 loss 0.02895408496260643\n",
      "Epoch 411/1000 loss 0.028795674443244934\n",
      "Epoch 412/1000 loss 0.02863813377916813\n",
      "Epoch 413/1000 loss 0.02848149836063385\n",
      "Epoch 414/1000 loss 0.028325658291578293\n",
      "Epoch 415/1000 loss 0.02817077934741974\n",
      "Epoch 416/1000 loss 0.028016677126288414\n",
      "Epoch 417/1000 loss 0.02786334976553917\n",
      "Epoch 418/1000 loss 0.02771110273897648\n",
      "Epoch 419/1000 loss 0.02755945362150669\n",
      "Epoch 420/1000 loss 0.027408629655838013\n",
      "Epoch 421/1000 loss 0.027258729562163353\n",
      "Epoch 422/1000 loss 0.027109647169709206\n",
      "Epoch 423/1000 loss 0.026961306110024452\n",
      "Epoch 424/1000 loss 0.026813749223947525\n",
      "Epoch 425/1000 loss 0.026667213067412376\n",
      "Epoch 426/1000 loss 0.02652132511138916\n",
      "Epoch 427/1000 loss 0.026376301422715187\n",
      "Epoch 428/1000 loss 0.026232000440359116\n",
      "Epoch 429/1000 loss 0.026088427752256393\n",
      "Epoch 430/1000 loss 0.02594580315053463\n",
      "Epoch 431/1000 loss 0.02580387331545353\n",
      "Epoch 432/1000 loss 0.025662656873464584\n",
      "Epoch 433/1000 loss 0.025522341951727867\n",
      "Epoch 434/1000 loss 0.025382766500115395\n",
      "Epoch 435/1000 loss 0.025243913754820824\n",
      "Epoch 436/1000 loss 0.02510581538081169\n",
      "Epoch 437/1000 loss 0.024968545883893967\n",
      "Epoch 438/1000 loss 0.024831967428326607\n",
      "Epoch 439/1000 loss 0.024696094915270805\n",
      "Epoch 440/1000 loss 0.02456095442175865\n",
      "Epoch 441/1000 loss 0.02442670240998268\n",
      "Epoch 442/1000 loss 0.024293020367622375\n",
      "Epoch 443/1000 loss 0.02416018769145012\n",
      "Epoch 444/1000 loss 0.02402793988585472\n",
      "Epoch 445/1000 loss 0.02389661595225334\n",
      "Epoch 446/1000 loss 0.023765843361616135\n",
      "Epoch 447/1000 loss 0.023635907098650932\n",
      "Epoch 448/1000 loss 0.023506605997681618\n",
      "Epoch 449/1000 loss 0.023377954959869385\n",
      "Epoch 450/1000 loss 0.023250099271535873\n",
      "Epoch 451/1000 loss 0.02312299981713295\n",
      "Epoch 452/1000 loss 0.02299651876091957\n",
      "Epoch 453/1000 loss 0.022870633751153946\n",
      "Epoch 454/1000 loss 0.022745531052350998\n",
      "Epoch 455/1000 loss 0.02262107841670513\n",
      "Epoch 456/1000 loss 0.02249736525118351\n",
      "Epoch 457/1000 loss 0.022374380379915237\n",
      "Epoch 458/1000 loss 0.022251853719353676\n",
      "Epoch 459/1000 loss 0.02213015779852867\n",
      "Epoch 460/1000 loss 0.022009141743183136\n",
      "Epoch 461/1000 loss 0.021888751536607742\n",
      "Epoch 462/1000 loss 0.021769050508737564\n",
      "Epoch 463/1000 loss 0.02164999023079872\n",
      "Epoch 464/1000 loss 0.0215314868837595\n",
      "Epoch 465/1000 loss 0.021413806825876236\n",
      "Epoch 466/1000 loss 0.02129661664366722\n",
      "Epoch 467/1000 loss 0.02118019200861454\n",
      "Epoch 468/1000 loss 0.021064331755042076\n",
      "Epoch 469/1000 loss 0.02094905450940132\n",
      "Epoch 470/1000 loss 0.02083449997007847\n",
      "Epoch 471/1000 loss 0.02072054147720337\n",
      "Epoch 472/1000 loss 0.020607084035873413\n",
      "Epoch 473/1000 loss 0.020494457334280014\n",
      "Epoch 474/1000 loss 0.020382340997457504\n",
      "Epoch 475/1000 loss 0.02027086168527603\n",
      "Epoch 476/1000 loss 0.020159903913736343\n",
      "Epoch 477/1000 loss 0.020049769431352615\n",
      "Epoch 478/1000 loss 0.019939949735999107\n",
      "Epoch 479/1000 loss 0.01983088068664074\n",
      "Epoch 480/1000 loss 0.019722426310181618\n",
      "Epoch 481/1000 loss 0.019614605233073235\n",
      "Epoch 482/1000 loss 0.019507290795445442\n",
      "Epoch 483/1000 loss 0.01940065249800682\n",
      "Epoch 484/1000 loss 0.01929444819688797\n",
      "Epoch 485/1000 loss 0.019188974052667618\n",
      "Epoch 486/1000 loss 0.019084004685282707\n",
      "Epoch 487/1000 loss 0.018979627639055252\n",
      "Epoch 488/1000 loss 0.018875764682888985\n",
      "Epoch 489/1000 loss 0.018772555515170097\n",
      "Epoch 490/1000 loss 0.01866982877254486\n",
      "Epoch 491/1000 loss 0.018567722290754318\n",
      "Epoch 492/1000 loss 0.018466191366314888\n",
      "Epoch 493/1000 loss 0.01836513541638851\n",
      "Epoch 494/1000 loss 0.018264759331941605\n",
      "Epoch 495/1000 loss 0.018164832144975662\n",
      "Epoch 496/1000 loss 0.018065428361296654\n",
      "Epoch 497/1000 loss 0.017966601997613907\n",
      "Epoch 498/1000 loss 0.017868345603346825\n",
      "Epoch 499/1000 loss 0.017770614475011826\n",
      "Epoch 500/1000 loss 0.017673376947641373\n",
      "Epoch 501/1000 loss 0.017576785758137703\n",
      "Epoch 502/1000 loss 0.017480578273534775\n",
      "Epoch 503/1000 loss 0.017384950071573257\n",
      "Epoch 504/1000 loss 0.01728992350399494\n",
      "Epoch 505/1000 loss 0.017195306718349457\n",
      "Epoch 506/1000 loss 0.017101269215345383\n",
      "Epoch 507/1000 loss 0.01700766384601593\n",
      "Epoch 508/1000 loss 0.01691472716629505\n",
      "Epoch 509/1000 loss 0.01682211086153984\n",
      "Epoch 510/1000 loss 0.016730139032006264\n",
      "Epoch 511/1000 loss 0.016638629138469696\n",
      "Epoch 512/1000 loss 0.016547655686736107\n",
      "Epoch 513/1000 loss 0.016457047313451767\n",
      "Epoch 514/1000 loss 0.01636703871190548\n",
      "Epoch 515/1000 loss 0.01627751626074314\n",
      "Epoch 516/1000 loss 0.016188429668545723\n",
      "Epoch 517/1000 loss 0.01609988883137703\n",
      "Epoch 518/1000 loss 0.016011802479624748\n",
      "Epoch 519/1000 loss 0.015924323350191116\n",
      "Epoch 520/1000 loss 0.015837140381336212\n",
      "Epoch 521/1000 loss 0.015750568360090256\n",
      "Epoch 522/1000 loss 0.01566440239548683\n",
      "Epoch 523/1000 loss 0.01557874958962202\n",
      "Epoch 524/1000 loss 0.015493495389819145\n",
      "Epoch 525/1000 loss 0.015408736653625965\n",
      "Epoch 526/1000 loss 0.015324425883591175\n",
      "Epoch 527/1000 loss 0.015240597538650036\n",
      "Epoch 528/1000 loss 0.015157249756157398\n",
      "Epoch 529/1000 loss 0.015074287541210651\n",
      "Epoch 530/1000 loss 0.014991949312388897\n",
      "Epoch 531/1000 loss 0.014909878373146057\n",
      "Epoch 532/1000 loss 0.01482835691422224\n",
      "Epoch 533/1000 loss 0.014747162349522114\n",
      "Epoch 534/1000 loss 0.014666502363979816\n",
      "Epoch 535/1000 loss 0.01458623819053173\n",
      "Epoch 536/1000 loss 0.014506558887660503\n",
      "Epoch 537/1000 loss 0.014427082613110542\n",
      "Epoch 538/1000 loss 0.014348292723298073\n",
      "Epoch 539/1000 loss 0.014269759878516197\n",
      "Epoch 540/1000 loss 0.014191744849085808\n",
      "Epoch 541/1000 loss 0.014114116318523884\n",
      "Epoch 542/1000 loss 0.014036856591701508\n",
      "Epoch 543/1000 loss 0.013960069045424461\n",
      "Epoch 544/1000 loss 0.013883711770176888\n",
      "Epoch 545/1000 loss 0.013807808980345726\n",
      "Epoch 546/1000 loss 0.013732245191931725\n",
      "Epoch 547/1000 loss 0.013657128438353539\n",
      "Epoch 548/1000 loss 0.013582390733063221\n",
      "Epoch 549/1000 loss 0.013508148491382599\n",
      "Epoch 550/1000 loss 0.013434238731861115\n",
      "Epoch 551/1000 loss 0.01336077880114317\n",
      "Epoch 552/1000 loss 0.013287638314068317\n",
      "Epoch 553/1000 loss 0.013215010054409504\n",
      "Epoch 554/1000 loss 0.013142712414264679\n",
      "Epoch 555/1000 loss 0.013070827350020409\n",
      "Epoch 556/1000 loss 0.012999320402741432\n",
      "Epoch 557/1000 loss 0.012928241863846779\n",
      "Epoch 558/1000 loss 0.012857464142143726\n",
      "Epoch 559/1000 loss 0.012787176296114922\n",
      "Epoch 560/1000 loss 0.012717239558696747\n",
      "Epoch 561/1000 loss 0.012647604569792747\n",
      "Epoch 562/1000 loss 0.012578512541949749\n",
      "Epoch 563/1000 loss 0.01250963844358921\n",
      "Epoch 564/1000 loss 0.012441139668226242\n",
      "Epoch 565/1000 loss 0.012373166158795357\n",
      "Epoch 566/1000 loss 0.012305526062846184\n",
      "Epoch 567/1000 loss 0.012238186784088612\n",
      "Epoch 568/1000 loss 0.012171268463134766\n",
      "Epoch 569/1000 loss 0.012104606255888939\n",
      "Epoch 570/1000 loss 0.012038445100188255\n",
      "Epoch 571/1000 loss 0.011972641572356224\n",
      "Epoch 572/1000 loss 0.011907065287232399\n",
      "Epoch 573/1000 loss 0.011841930449008942\n",
      "Epoch 574/1000 loss 0.011777268722653389\n",
      "Epoch 575/1000 loss 0.011712796986103058\n",
      "Epoch 576/1000 loss 0.011648714542388916\n",
      "Epoch 577/1000 loss 0.01158500462770462\n",
      "Epoch 578/1000 loss 0.011521641165018082\n",
      "Epoch 579/1000 loss 0.011458569206297398\n",
      "Epoch 580/1000 loss 0.01139595452696085\n",
      "Epoch 581/1000 loss 0.011333629488945007\n",
      "Epoch 582/1000 loss 0.011271621100604534\n",
      "Epoch 583/1000 loss 0.011209893971681595\n",
      "Epoch 584/1000 loss 0.011148618534207344\n",
      "Epoch 585/1000 loss 0.011087646707892418\n",
      "Epoch 586/1000 loss 0.011026991531252861\n",
      "Epoch 587/1000 loss 0.010966667905449867\n",
      "Epoch 588/1000 loss 0.010906649753451347\n",
      "Epoch 589/1000 loss 0.010846996679902077\n",
      "Epoch 590/1000 loss 0.010787740349769592\n",
      "Epoch 591/1000 loss 0.010728723369538784\n",
      "Epoch 592/1000 loss 0.010670074261724949\n",
      "Epoch 593/1000 loss 0.010611672885715961\n",
      "Epoch 594/1000 loss 0.010553550906479359\n",
      "Epoch 595/1000 loss 0.010495880618691444\n",
      "Epoch 596/1000 loss 0.010438438504934311\n",
      "Epoch 597/1000 loss 0.010381324216723442\n",
      "Epoch 598/1000 loss 0.010324515402317047\n",
      "Epoch 599/1000 loss 0.010268125683069229\n",
      "Epoch 600/1000 loss 0.010211942717432976\n",
      "Epoch 601/1000 loss 0.010156037285923958\n",
      "Epoch 602/1000 loss 0.010100525803864002\n",
      "Epoch 603/1000 loss 0.010045258328318596\n",
      "Epoch 604/1000 loss 0.009990333579480648\n",
      "Epoch 605/1000 loss 0.00993564072996378\n",
      "Epoch 606/1000 loss 0.00988132692873478\n",
      "Epoch 607/1000 loss 0.009827236644923687\n",
      "Epoch 608/1000 loss 0.009773465804755688\n",
      "Epoch 609/1000 loss 0.009720039553940296\n",
      "Epoch 610/1000 loss 0.00966690294444561\n",
      "Epoch 611/1000 loss 0.009614048525691032\n",
      "Epoch 612/1000 loss 0.009561429731547832\n",
      "Epoch 613/1000 loss 0.009509126655757427\n",
      "Epoch 614/1000 loss 0.009457125328481197\n",
      "Epoch 615/1000 loss 0.009405402466654778\n",
      "Epoch 616/1000 loss 0.009353955276310444\n",
      "Epoch 617/1000 loss 0.009302749298512936\n",
      "Epoch 618/1000 loss 0.009251833893358707\n",
      "Epoch 619/1000 loss 0.009201223030686378\n",
      "Epoch 620/1000 loss 0.009150886908173561\n",
      "Epoch 621/1000 loss 0.009100859053432941\n",
      "Epoch 622/1000 loss 0.009051079861819744\n",
      "Epoch 623/1000 loss 0.009001612663269043\n",
      "Epoch 624/1000 loss 0.008952280506491661\n",
      "Epoch 625/1000 loss 0.008903352543711662\n",
      "Epoch 626/1000 loss 0.008854715153574944\n",
      "Epoch 627/1000 loss 0.008806241676211357\n",
      "Epoch 628/1000 loss 0.008758047595620155\n",
      "Epoch 629/1000 loss 0.008710184134542942\n",
      "Epoch 630/1000 loss 0.008662481792271137\n",
      "Epoch 631/1000 loss 0.008615130558609962\n",
      "Epoch 632/1000 loss 0.008567972108721733\n",
      "Epoch 633/1000 loss 0.008521134965121746\n",
      "Epoch 634/1000 loss 0.008474500849843025\n",
      "Epoch 635/1000 loss 0.008428179658949375\n",
      "Epoch 636/1000 loss 0.008382066152989864\n",
      "Epoch 637/1000 loss 0.008336139842867851\n",
      "Epoch 638/1000 loss 0.008290615864098072\n",
      "Epoch 639/1000 loss 0.008245272561907768\n",
      "Epoch 640/1000 loss 0.008200163953006268\n",
      "Epoch 641/1000 loss 0.00815531425178051\n",
      "Epoch 642/1000 loss 0.008110695518553257\n",
      "Epoch 643/1000 loss 0.008066335693001747\n",
      "Epoch 644/1000 loss 0.008022159337997437\n",
      "Epoch 645/1000 loss 0.007978323847055435\n",
      "Epoch 646/1000 loss 0.007934640161693096\n",
      "Epoch 647/1000 loss 0.007891292683780193\n",
      "Epoch 648/1000 loss 0.007848141714930534\n",
      "Epoch 649/1000 loss 0.007805184926837683\n",
      "Epoch 650/1000 loss 0.007762539200484753\n",
      "Epoch 651/1000 loss 0.007720020599663258\n",
      "Epoch 652/1000 loss 0.007677784655243158\n",
      "Epoch 653/1000 loss 0.007635819725692272\n",
      "Epoch 654/1000 loss 0.007594051770865917\n",
      "Epoch 655/1000 loss 0.007552494760602713\n",
      "Epoch 656/1000 loss 0.0075111351907253265\n",
      "Epoch 657/1000 loss 0.007470103446394205\n",
      "Epoch 658/1000 loss 0.007429224904626608\n",
      "Epoch 659/1000 loss 0.007388610392808914\n",
      "Epoch 660/1000 loss 0.007348206825554371\n",
      "Epoch 661/1000 loss 0.0073079438880085945\n",
      "Epoch 662/1000 loss 0.007267969194799662\n",
      "Epoch 663/1000 loss 0.007228261325508356\n",
      "Epoch 664/1000 loss 0.007188682444393635\n",
      "Epoch 665/1000 loss 0.007149445824325085\n",
      "Epoch 666/1000 loss 0.007110279984772205\n",
      "Epoch 667/1000 loss 0.007071393076330423\n",
      "Epoch 668/1000 loss 0.007032718509435654\n",
      "Epoch 669/1000 loss 0.006994279567152262\n",
      "Epoch 670/1000 loss 0.00695596169680357\n",
      "Epoch 671/1000 loss 0.006917929742485285\n",
      "Epoch 672/1000 loss 0.006880080793052912\n",
      "Epoch 673/1000 loss 0.006842504255473614\n",
      "Epoch 674/1000 loss 0.006805048789829016\n",
      "Epoch 675/1000 loss 0.0067678047344088554\n",
      "Epoch 676/1000 loss 0.006730781402438879\n",
      "Epoch 677/1000 loss 0.006693935487419367\n",
      "Epoch 678/1000 loss 0.006657368503510952\n",
      "Epoch 679/1000 loss 0.006621009204536676\n",
      "Epoch 680/1000 loss 0.006584709044545889\n",
      "Epoch 681/1000 loss 0.006548742298036814\n",
      "Epoch 682/1000 loss 0.006512898951768875\n",
      "Epoch 683/1000 loss 0.006477280054241419\n",
      "Epoch 684/1000 loss 0.006441825069487095\n",
      "Epoch 685/1000 loss 0.0064065768383443356\n",
      "Epoch 686/1000 loss 0.006371601019054651\n",
      "Epoch 687/1000 loss 0.006336746271699667\n",
      "Epoch 688/1000 loss 0.006302066147327423\n",
      "Epoch 689/1000 loss 0.006267555058002472\n",
      "Epoch 690/1000 loss 0.00623330706730485\n",
      "Epoch 691/1000 loss 0.006199203431606293\n",
      "Epoch 692/1000 loss 0.006165281869471073\n",
      "Epoch 693/1000 loss 0.006131517700850964\n",
      "Epoch 694/1000 loss 0.006098006386309862\n",
      "Epoch 695/1000 loss 0.006064600311219692\n",
      "Epoch 696/1000 loss 0.006031467579305172\n",
      "Epoch 697/1000 loss 0.005998475942760706\n",
      "Epoch 698/1000 loss 0.005965673830360174\n",
      "Epoch 699/1000 loss 0.005933104548603296\n",
      "Epoch 700/1000 loss 0.005900637712329626\n",
      "Epoch 701/1000 loss 0.005868332460522652\n",
      "Epoch 702/1000 loss 0.005836186930537224\n",
      "Epoch 703/1000 loss 0.005804268643260002\n",
      "Epoch 704/1000 loss 0.005772562697529793\n",
      "Epoch 705/1000 loss 0.005740999709814787\n",
      "Epoch 706/1000 loss 0.005709574092179537\n",
      "Epoch 707/1000 loss 0.00567830353975296\n",
      "Epoch 708/1000 loss 0.005647295154631138\n",
      "Epoch 709/1000 loss 0.005616350565105677\n",
      "Epoch 710/1000 loss 0.005585632286965847\n",
      "Epoch 711/1000 loss 0.005555091425776482\n",
      "Epoch 712/1000 loss 0.005524766631424427\n",
      "Epoch 713/1000 loss 0.005494499113410711\n",
      "Epoch 714/1000 loss 0.0054644192568957806\n",
      "Epoch 715/1000 loss 0.005434579215943813\n",
      "Epoch 716/1000 loss 0.00540483882650733\n",
      "Epoch 717/1000 loss 0.005375261884182692\n",
      "Epoch 718/1000 loss 0.005345836281776428\n",
      "Epoch 719/1000 loss 0.005316619761288166\n",
      "Epoch 720/1000 loss 0.0052875494584441185\n",
      "Epoch 721/1000 loss 0.005258652381598949\n",
      "Epoch 722/1000 loss 0.005229854490607977\n",
      "Epoch 723/1000 loss 0.005201259162276983\n",
      "Epoch 724/1000 loss 0.005172771401703358\n",
      "Epoch 725/1000 loss 0.005144460592418909\n",
      "Epoch 726/1000 loss 0.005116414278745651\n",
      "Epoch 727/1000 loss 0.005088373553007841\n",
      "Epoch 728/1000 loss 0.005060589872300625\n",
      "Epoch 729/1000 loss 0.005032861139625311\n",
      "Epoch 730/1000 loss 0.005005338229238987\n",
      "Epoch 731/1000 loss 0.004977957345545292\n",
      "Epoch 732/1000 loss 0.004950718488544226\n",
      "Epoch 733/1000 loss 0.004923664499074221\n",
      "Epoch 734/1000 loss 0.004896738566458225\n",
      "Epoch 735/1000 loss 0.0048699514009058475\n",
      "Epoch 736/1000 loss 0.004843305330723524\n",
      "Epoch 737/1000 loss 0.004816781263798475\n",
      "Epoch 738/1000 loss 0.004790476523339748\n",
      "Epoch 739/1000 loss 0.004764228127896786\n",
      "Epoch 740/1000 loss 0.004738184157758951\n",
      "Epoch 741/1000 loss 0.004712275695055723\n",
      "Epoch 742/1000 loss 0.004686507396399975\n",
      "Epoch 743/1000 loss 0.004660895559936762\n",
      "Epoch 744/1000 loss 0.004635404795408249\n",
      "Epoch 745/1000 loss 0.004610033240169287\n",
      "Epoch 746/1000 loss 0.004584790673106909\n",
      "Epoch 747/1000 loss 0.004559702705591917\n",
      "Epoch 748/1000 loss 0.004534774925559759\n",
      "Epoch 749/1000 loss 0.0045099700801074505\n",
      "Epoch 750/1000 loss 0.004485312849283218\n",
      "Epoch 751/1000 loss 0.004460749216377735\n",
      "Epoch 752/1000 loss 0.004436374641954899\n",
      "Epoch 753/1000 loss 0.0044120969250798225\n",
      "Epoch 754/1000 loss 0.004387970082461834\n",
      "Epoch 755/1000 loss 0.00436397735029459\n",
      "Epoch 756/1000 loss 0.004340041428804398\n",
      "Epoch 757/1000 loss 0.004316334612667561\n",
      "Epoch 758/1000 loss 0.004292749334126711\n",
      "Epoch 759/1000 loss 0.004269278608262539\n",
      "Epoch 760/1000 loss 0.004245903342962265\n",
      "Epoch 761/1000 loss 0.004222695715725422\n",
      "Epoch 762/1000 loss 0.004199570044875145\n",
      "Epoch 763/1000 loss 0.004176616203039885\n",
      "Epoch 764/1000 loss 0.004153777379542589\n",
      "Epoch 765/1000 loss 0.00413105171173811\n",
      "Epoch 766/1000 loss 0.004108489956706762\n",
      "Epoch 767/1000 loss 0.004086006432771683\n",
      "Epoch 768/1000 loss 0.004063631407916546\n",
      "Epoch 769/1000 loss 0.004041402600705624\n",
      "Epoch 770/1000 loss 0.004019294399768114\n",
      "Epoch 771/1000 loss 0.003997324965894222\n",
      "Epoch 772/1000 loss 0.00397544214501977\n",
      "Epoch 773/1000 loss 0.003953685984015465\n",
      "Epoch 774/1000 loss 0.003932081162929535\n",
      "Epoch 775/1000 loss 0.003910551778972149\n",
      "Epoch 776/1000 loss 0.0038891476579010487\n",
      "Epoch 777/1000 loss 0.0038679013960063457\n",
      "Epoch 778/1000 loss 0.0038467426784336567\n",
      "Epoch 779/1000 loss 0.003825690597295761\n",
      "Epoch 780/1000 loss 0.0038047675043344498\n",
      "Epoch 781/1000 loss 0.0037839494179934263\n",
      "Epoch 782/1000 loss 0.0037632682360708714\n",
      "Epoch 783/1000 loss 0.0037426911294460297\n",
      "Epoch 784/1000 loss 0.0037222120445221663\n",
      "Epoch 785/1000 loss 0.0037018645089119673\n",
      "Epoch 786/1000 loss 0.0036815758794546127\n",
      "Epoch 787/1000 loss 0.003661497961729765\n",
      "Epoch 788/1000 loss 0.003641433548182249\n",
      "Epoch 789/1000 loss 0.0036214899737387896\n",
      "Epoch 790/1000 loss 0.003601687029004097\n",
      "Epoch 791/1000 loss 0.0035820063203573227\n",
      "Epoch 792/1000 loss 0.0035623840522021055\n",
      "Epoch 793/1000 loss 0.003542934311553836\n",
      "Epoch 794/1000 loss 0.003523529041558504\n",
      "Epoch 795/1000 loss 0.0035042916424572468\n",
      "Epoch 796/1000 loss 0.0034850898664444685\n",
      "Epoch 797/1000 loss 0.003466018009930849\n",
      "Epoch 798/1000 loss 0.0034471109975129366\n",
      "Epoch 799/1000 loss 0.0034282426349818707\n",
      "Epoch 800/1000 loss 0.003409454133361578\n",
      "Epoch 801/1000 loss 0.0033908162731677294\n",
      "Epoch 802/1000 loss 0.003372256178408861\n",
      "Epoch 803/1000 loss 0.0033538485877215862\n",
      "Epoch 804/1000 loss 0.003335503861308098\n",
      "Epoch 805/1000 loss 0.0033172282855957747\n",
      "Epoch 806/1000 loss 0.003299109172075987\n",
      "Epoch 807/1000 loss 0.0032810415141284466\n",
      "Epoch 808/1000 loss 0.0032630632631480694\n",
      "Epoch 809/1000 loss 0.0032452468294650316\n",
      "Epoch 810/1000 loss 0.0032275053672492504\n",
      "Epoch 811/1000 loss 0.0032098456285893917\n",
      "Epoch 812/1000 loss 0.0031923234928399324\n",
      "Epoch 813/1000 loss 0.003174819750711322\n",
      "Epoch 814/1000 loss 0.0031575020402669907\n",
      "Epoch 815/1000 loss 0.003140190616250038\n",
      "Epoch 816/1000 loss 0.003123020986095071\n",
      "Epoch 817/1000 loss 0.0031059395987540483\n",
      "Epoch 818/1000 loss 0.003088935511186719\n",
      "Epoch 819/1000 loss 0.003072040621191263\n",
      "Epoch 820/1000 loss 0.0030552479438483715\n",
      "Epoch 821/1000 loss 0.00303855212405324\n",
      "Epoch 822/1000 loss 0.0030219326727092266\n",
      "Epoch 823/1000 loss 0.0030054054223001003\n",
      "Epoch 824/1000 loss 0.0029889445286244154\n",
      "Epoch 825/1000 loss 0.0029726161155849695\n",
      "Epoch 826/1000 loss 0.002956333104521036\n",
      "Epoch 827/1000 loss 0.002940184436738491\n",
      "Epoch 828/1000 loss 0.0029241309966892004\n",
      "Epoch 829/1000 loss 0.002908105496317148\n",
      "Epoch 830/1000 loss 0.0028922082856297493\n",
      "Epoch 831/1000 loss 0.002876385347917676\n",
      "Epoch 832/1000 loss 0.0028606492560356855\n",
      "Epoch 833/1000 loss 0.0028450076933950186\n",
      "Epoch 834/1000 loss 0.0028294511139392853\n",
      "Epoch 835/1000 loss 0.002813958562910557\n",
      "Epoch 836/1000 loss 0.002798557747155428\n",
      "Epoch 837/1000 loss 0.0027832542546093464\n",
      "Epoch 838/1000 loss 0.0027680264320224524\n",
      "Epoch 839/1000 loss 0.0027528838254511356\n",
      "Epoch 840/1000 loss 0.0027378287632018328\n",
      "Epoch 841/1000 loss 0.0027228505350649357\n",
      "Epoch 842/1000 loss 0.0027079519350081682\n",
      "Epoch 843/1000 loss 0.0026931334286928177\n",
      "Epoch 844/1000 loss 0.0026784229557961226\n",
      "Epoch 845/1000 loss 0.002663732273504138\n",
      "Epoch 846/1000 loss 0.002649195957928896\n",
      "Epoch 847/1000 loss 0.0026347264647483826\n",
      "Epoch 848/1000 loss 0.002620286773890257\n",
      "Epoch 849/1000 loss 0.0026059472002089024\n",
      "Epoch 850/1000 loss 0.0025916914455592632\n",
      "Epoch 851/1000 loss 0.002577508334070444\n",
      "Epoch 852/1000 loss 0.0025634262710809708\n",
      "Epoch 853/1000 loss 0.0025493991561233997\n",
      "Epoch 854/1000 loss 0.0025354616809636354\n",
      "Epoch 855/1000 loss 0.002521584276109934\n",
      "Epoch 856/1000 loss 0.0025077792815864086\n",
      "Epoch 857/1000 loss 0.0024940764997154474\n",
      "Epoch 858/1000 loss 0.002480412134900689\n",
      "Epoch 859/1000 loss 0.00246685603633523\n",
      "Epoch 860/1000 loss 0.002453362103551626\n",
      "Epoch 861/1000 loss 0.0024399191606789827\n",
      "Epoch 862/1000 loss 0.0024266038089990616\n",
      "Epoch 863/1000 loss 0.0024133340921252966\n",
      "Epoch 864/1000 loss 0.0024001484271138906\n",
      "Epoch 865/1000 loss 0.002386973239481449\n",
      "Epoch 866/1000 loss 0.002373951021581888\n",
      "Epoch 867/1000 loss 0.0023609341587871313\n",
      "Epoch 868/1000 loss 0.002348038600757718\n",
      "Epoch 869/1000 loss 0.0023351875133812428\n",
      "Epoch 870/1000 loss 0.0023224034812301397\n",
      "Epoch 871/1000 loss 0.002309713512659073\n",
      "Epoch 872/1000 loss 0.002297067316249013\n",
      "Epoch 873/1000 loss 0.0022845170460641384\n",
      "Epoch 874/1000 loss 0.0022720033302903175\n",
      "Epoch 875/1000 loss 0.0022595778573304415\n",
      "Epoch 876/1000 loss 0.0022472047712653875\n",
      "Epoch 877/1000 loss 0.0022349462378770113\n",
      "Epoch 878/1000 loss 0.00222269375808537\n",
      "Epoch 879/1000 loss 0.0022105476818978786\n",
      "Epoch 880/1000 loss 0.002198467729613185\n",
      "Epoch 881/1000 loss 0.0021864145528525114\n",
      "Epoch 882/1000 loss 0.0021745061967521906\n",
      "Epoch 883/1000 loss 0.002162560820579529\n",
      "Epoch 884/1000 loss 0.002150756772607565\n",
      "Epoch 885/1000 loss 0.00213897367939353\n",
      "Epoch 886/1000 loss 0.002127292100340128\n",
      "Epoch 887/1000 loss 0.0021156591828912497\n",
      "Epoch 888/1000 loss 0.0021040858700871468\n",
      "Epoch 889/1000 loss 0.0020925651770085096\n",
      "Epoch 890/1000 loss 0.0020811310969293118\n",
      "Epoch 891/1000 loss 0.0020697382278740406\n",
      "Epoch 892/1000 loss 0.002058399375528097\n",
      "Epoch 893/1000 loss 0.0020471648313105106\n",
      "Epoch 894/1000 loss 0.002035952638834715\n",
      "Epoch 895/1000 loss 0.0020248040091246367\n",
      "Epoch 896/1000 loss 0.0020137419924139977\n",
      "Epoch 897/1000 loss 0.002002742839977145\n",
      "Epoch 898/1000 loss 0.001991777215152979\n",
      "Epoch 899/1000 loss 0.0019808891229331493\n",
      "Epoch 900/1000 loss 0.0019700322300195694\n",
      "Epoch 901/1000 loss 0.001959268469363451\n",
      "Epoch 902/1000 loss 0.0019485510420054197\n",
      "Epoch 903/1000 loss 0.001937889726832509\n",
      "Epoch 904/1000 loss 0.0019272720674052835\n",
      "Epoch 905/1000 loss 0.0019167512655258179\n",
      "Epoch 906/1000 loss 0.001906252233311534\n",
      "Epoch 907/1000 loss 0.0018958222353830934\n",
      "Epoch 908/1000 loss 0.0018854765221476555\n",
      "Epoch 909/1000 loss 0.0018751658499240875\n",
      "Epoch 910/1000 loss 0.0018648987170308828\n",
      "Epoch 911/1000 loss 0.001854680827818811\n",
      "Epoch 912/1000 loss 0.0018445346504449844\n",
      "Epoch 913/1000 loss 0.001834458322264254\n",
      "Epoch 914/1000 loss 0.0018244184320792556\n",
      "Epoch 915/1000 loss 0.0018144476925954223\n",
      "Epoch 916/1000 loss 0.001804521307349205\n",
      "Epoch 917/1000 loss 0.0017946443986147642\n",
      "Epoch 918/1000 loss 0.0017848231364041567\n",
      "Epoch 919/1000 loss 0.0017750828992575407\n",
      "Epoch 920/1000 loss 0.0017653715331107378\n",
      "Epoch 921/1000 loss 0.0017557160463184118\n",
      "Epoch 922/1000 loss 0.0017460996750742197\n",
      "Epoch 923/1000 loss 0.0017365397652611136\n",
      "Epoch 924/1000 loss 0.0017270317766815424\n",
      "Epoch 925/1000 loss 0.001717600622214377\n",
      "Epoch 926/1000 loss 0.0017082203412428498\n",
      "Epoch 927/1000 loss 0.0016988806892186403\n",
      "Epoch 928/1000 loss 0.0016895690932869911\n",
      "Epoch 929/1000 loss 0.0016803254839032888\n",
      "Epoch 930/1000 loss 0.0016711382195353508\n",
      "Epoch 931/1000 loss 0.0016619969392195344\n",
      "Epoch 932/1000 loss 0.0016529109561815858\n",
      "Epoch 933/1000 loss 0.0016438653692603111\n",
      "Epoch 934/1000 loss 0.0016348666977137327\n",
      "Epoch 935/1000 loss 0.001625938923098147\n",
      "Epoch 936/1000 loss 0.0016170215094462037\n",
      "Epoch 937/1000 loss 0.0016081947833299637\n",
      "Epoch 938/1000 loss 0.0015993767883628607\n",
      "Epoch 939/1000 loss 0.0015906434273347259\n",
      "Epoch 940/1000 loss 0.001581941731274128\n",
      "Epoch 941/1000 loss 0.0015732767060399055\n",
      "Epoch 942/1000 loss 0.0015646690735593438\n",
      "Epoch 943/1000 loss 0.001556082395836711\n",
      "Epoch 944/1000 loss 0.0015475917607545853\n",
      "Epoch 945/1000 loss 0.0015391238266602159\n",
      "Epoch 946/1000 loss 0.0015306997811421752\n",
      "Epoch 947/1000 loss 0.001522344769909978\n",
      "Epoch 948/1000 loss 0.001514009083621204\n",
      "Epoch 949/1000 loss 0.0015057337004691362\n",
      "Epoch 950/1000 loss 0.001497492310591042\n",
      "Epoch 951/1000 loss 0.001489310641773045\n",
      "Epoch 952/1000 loss 0.001481141778640449\n",
      "Epoch 953/1000 loss 0.0014730477705597878\n",
      "Epoch 954/1000 loss 0.0014649903168901801\n",
      "Epoch 955/1000 loss 0.0014569887425750494\n",
      "Epoch 956/1000 loss 0.001449025934562087\n",
      "Epoch 957/1000 loss 0.001441087108105421\n",
      "Epoch 958/1000 loss 0.0014332069549709558\n",
      "Epoch 959/1000 loss 0.0014253852423280478\n",
      "Epoch 960/1000 loss 0.001417565974406898\n",
      "Epoch 961/1000 loss 0.0014098073588684201\n",
      "Epoch 962/1000 loss 0.0014021038077771664\n",
      "Epoch 963/1000 loss 0.0013944387901574373\n",
      "Epoch 964/1000 loss 0.0013868180103600025\n",
      "Epoch 965/1000 loss 0.001379219233058393\n",
      "Epoch 966/1000 loss 0.0013716730754822493\n",
      "Epoch 967/1000 loss 0.0013641836121678352\n",
      "Epoch 968/1000 loss 0.0013567004352807999\n",
      "Epoch 969/1000 loss 0.001349295605905354\n",
      "Epoch 970/1000 loss 0.0013419107999652624\n",
      "Epoch 971/1000 loss 0.0013345731422305107\n",
      "Epoch 972/1000 loss 0.0013272692449390888\n",
      "Epoch 973/1000 loss 0.0013200055109336972\n",
      "Epoch 974/1000 loss 0.0013127996353432536\n",
      "Epoch 975/1000 loss 0.0013056198367848992\n",
      "Epoch 976/1000 loss 0.0012984697241336107\n",
      "Epoch 977/1000 loss 0.0012913753744214773\n",
      "Epoch 978/1000 loss 0.001284281024709344\n",
      "Epoch 979/1000 loss 0.0012772846966981888\n",
      "Epoch 980/1000 loss 0.0012702890671789646\n",
      "Epoch 981/1000 loss 0.001263355603441596\n",
      "Epoch 982/1000 loss 0.0012564464705064893\n",
      "Epoch 983/1000 loss 0.001249555149115622\n",
      "Epoch 984/1000 loss 0.001242718892171979\n",
      "Epoch 985/1000 loss 0.0012359387474134564\n",
      "Epoch 986/1000 loss 0.0012291603488847613\n",
      "Epoch 987/1000 loss 0.0012224584352225065\n",
      "Epoch 988/1000 loss 0.0012157652527093887\n",
      "Epoch 989/1000 loss 0.001209101639688015\n",
      "Epoch 990/1000 loss 0.0012024935567751527\n",
      "Epoch 991/1000 loss 0.0011959131807088852\n",
      "Epoch 992/1000 loss 0.0011893793707713485\n",
      "Epoch 993/1000 loss 0.0011828638380393386\n",
      "Epoch 994/1000 loss 0.0011764077935367823\n",
      "Epoch 995/1000 loss 0.001169974566437304\n",
      "Epoch 996/1000 loss 0.0011635712580755353\n",
      "Epoch 997/1000 loss 0.001157193211838603\n",
      "Epoch 998/1000 loss 0.001150882220827043\n",
      "Epoch 999/1000 loss 0.0011445863638073206\n",
      "Parameter containing:\n",
      "tensor([[0.9815, 2.0101],\n",
      "        [3.0778, 3.9574]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "#Set Up\n",
    "x = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "\n",
    "W_true = torch.tensor(W_true, dtype=torch.float32)\n",
    "\n",
    "W = (torch.randn(2, 2, dtype=torch.float32, requires_grad=True))\n",
    "W = nn.Parameter(W)\n",
    "\n",
    "y = torch.zeros(x.shape[0], x.shape[1])\n",
    "\n",
    "for i in range(x.shape[0]):\n",
    "    y[i] = torch.matmul(W_true, x[i])\n",
    "\n",
    "W = (torch.randn(2, 2, dtype=torch.float32, requires_grad=True))\n",
    "W = nn.Parameter(W)\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "\n",
    "    def __init__(self, W):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.W = W\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.matmul(self.W, x)\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = MyModel(W=W)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "n_iters = 1000\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    #Forward pass\n",
    "    y_pred = torch.zeros(x.shape[0], x.shape[1])\n",
    "    for i in range(x.shape[0]):\n",
    "        y_pred[i] = model(x[i])\n",
    "\n",
    "    #loss\n",
    "    l = loss(y, y_pred)\n",
    "\n",
    "    #Gradient\n",
    "    l.backward()\n",
    "\n",
    "    #Update\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    print(f\"Epoch {epoch}/{n_iters} loss {l}\")\n",
    "\n",
    "#for name, param in model.named_parameters():  # To see params\n",
    "#    if param.requires_grad:\n",
    "#        print (name, param.data)\n",
    "\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we converge to the correct matrix! Wonderful! Let complexify a last time our model by adding a simgoid function :\n",
    "\n",
    "$\\vec{y} = \\sigma(\\mathbf{W}\\vec{x})$\n",
    "\n",
    "Let's begin by creating our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.47262316e-03, 6.14417460e-06],\n",
       "       [5.42916316e-03, 3.87672979e-05],\n",
       "       [1.18787699e-02, 2.44563867e-04],\n",
       "       [2.57915356e-02, 1.54114975e-03],\n",
       "       [5.50908438e-02, 9.64542862e-03],\n",
       "       [1.13786745e-01, 5.78956558e-02],\n",
       "       [2.20430757e-01, 2.79414362e-01],\n",
       "       [3.83744612e-01, 7.09866722e-01],\n",
       "       [5.78297773e-01, 9.39165926e-01],\n",
       "       [7.51244963e-01, 9.89838617e-01],\n",
       "       [8.69294680e-01, 9.98375700e-01],\n",
       "       [9.36088489e-01, 9.99742223e-01],\n",
       "       [9.69929659e-01, 9.99959138e-01],\n",
       "       [9.86117657e-01, 9.99993524e-01],\n",
       "       [9.93648115e-01, 9.99998974e-01],\n",
       "       [9.97105676e-01, 9.99999837e-01],\n",
       "       [9.98683655e-01, 9.99999974e-01],\n",
       "       [9.99401839e-01, 9.99999996e-01],\n",
       "       [9.99728296e-01, 9.99999999e-01],\n",
       "       [9.99876605e-01, 1.00000000e+00]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.linspace(0, 5, 20)\n",
    "x2 = np.linspace(-3, 2, 20)\n",
    "\n",
    "X = np.array([x1, x2]).T\n",
    "\n",
    "W_true = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "y = np.zeros((X.shape[0], X.shape[1]))\n",
    "\n",
    "sigma = lambda x: ((1+np.exp(-x))**(-1))\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    y[i] = sigma(W_true @ X[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\AppData\\Local\\Temp/ipykernel_8872/1939226080.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  W_true = torch.tensor(W_true, dtype=torch.float32)\n",
      "C:\\Users\\antho\\AppData\\Local\\Temp/ipykernel_8872/1939226080.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[1.0000, 2.0000],\n",
      "        [2.9997, 3.9996]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Set up\n",
    "\n",
    "x = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "W_true = torch.tensor(W_true, dtype=torch.float32)\n",
    "\n",
    "W = torch.randn(2, 2, dtype=torch.float32, requires_grad=True)\n",
    "#W = torch.tensor([[10, 10], [10, 10]], dtype=torch.float32, requires_grad=True)\n",
    "W = nn.Parameter(W)\n",
    "\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "\n",
    "    def __init__(self, W):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.W = W\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(torch.matmul(self.W, x))\n",
    "\n",
    "learning_rate = 30\n",
    "\n",
    "model = MyModel(W=W)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "n_iters = 1000\n",
    "\n",
    "Total_lost = []\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    #Forward pass\n",
    "    y_pred = torch.zeros(x.shape[0], x.shape[1])\n",
    "    for i in range(x.shape[0]):\n",
    "        y_pred[i] = model(x[i])\n",
    "\n",
    "    #loss\n",
    "    l = loss(y, y_pred)\n",
    "\n",
    "    #Gradient\n",
    "    l.backward()\n",
    "\n",
    "    #Update\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    Total_lost.append(l.detach().numpy())\n",
    "\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We converge to the correct answer! Wonderful! However, we have to increase our learning rate. This is because our range of value is small (always between 0 and 1), therefore, a small difference in the loss function is actually more significative! A learning rate of 0.01 was not able to converge to the correct answer. A learning rate of 10 or 100 seems to work. We would need to refine our model to find the perfect learning rate because the loss function increase a little bit per moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t = np.linspace(0, n_iters, len(Total_lost))\n",
    "\n",
    "\n",
    "plt.plot(t, Total_lost, \"r-\", label=\"Loss function with a lr=30\")\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(shadow=True, fancybox=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9eaceb9a2ec0e7a70132c062f26382ea71ab72be3751535a08625cae626faf1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
